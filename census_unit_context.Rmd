---
title: "Census - Unit and Context"
author: "Dan Price"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
geometry: margin=1in
fontsize: 11pt
documentclass: article
header-includes: 
  - \usepackage{tikz}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, include=TRUE)
```
## Context and Unit

# Using the Census to Represent Society
Over the last several years, we have been asking how to better represent the strengths of both individuals and communities when crafting public health interventions - either education, improving access, or changing behaviors. For several decades, public health officials has framed their evaluations around the social determinants of health, which risk casting people and groups as merely victims of dynamics beyond their control. From a rhetorical standpoint, they were responding against a moral argument that all health and personal outcomes in life are somehow related back to individual responsibility, which makes an immediate sense when one looks around and sees, for example, that one child does better than a sibling, but which cannot explain the stunning inequities in outcomes across groups when comparing whole populations statistically. 

Many philosophers have long been convinced that there was a framing problem hidden in the presupposition that description involved the dispassionate placement of individual cases in their proper place, as determined by a protocol or algorithm that assigned a name or categorization to each individual. To simply give up on that project of characterizing and speaking about the world, however, seemed unforgivably self-indulgent. To just repeat poetry that denounced the crimes against the individual seemed precious and ineffectual. The celebration of the individual's creative capacity, both through and against the expectations of a broader culture, would be merely empty praise without some way of understanding, in precise and replicable ways, how to measure and assess what the individual was doing that counted as creative and innovative. The play between passively receiving and actively producing - in, through, and against culture - came to seem to be part of the framing problem. How could we use the interchange between active and passive as a fluid and generative space for understanding how possibilities are displayed and decisions made, before they were calcified as a schema for placing individuals into a box?

The task is to create an honest account of how people face barriers in their lives and to identify places where interventions reduce barriers and expand capacity instead of merely shifting burdens. The initial step is to understand some of the limits of the current approach to representing data about communities and individuals.

We start by looking at how the data is made available from the census. We look first at the data that was first published after the 2020 decennial census, which is the closest to the raw counts you can access publicly. These are published as quickly as possible after collection, in order to help with the redistricting process in each state, and the first table we look at has raw counts of individual people in the smallest geographic areas they make public, the census block group. (https://www.census.gov/programs-surveys/geography/about/glossary.html#par_textimage_4). The block groups are subdivisions within census tracts and are defined by a process that allows aggregation by geography. Since tracts never cross state or county lines, you can aggregate up through those units. Cities and zip codes, although more commonly recognized by people in a community, don't always aggregate smoothly by tract.  

```{r prelims, include=FALSE}
library(knitr)
library(tidyr)
library(dplyr)
library(stringr)
library(data.table)
library(sf)
maindir = "~/Downloads/UH_OneDrive/OneDrive\ -\ University\ Of\ Houston/Social\ Network\ Hypergraphs/" #Dan at home
#maindir = "~/OneDrive\ -\ University\ Of\ Houston/Social\ Network\ Hypergraphs/" #Dan at work
housingdir = paste0(maindir,"HCAD/")
houstondatadir = paste0(maindir,"HoustonCityData/") 
censusdir = paste0(maindir,"Census/") 
vintage = "2020"
state = 48 #48 Texas; 22 Louisiana
county = 201 #8 county region: 201 Harris; 157 Fort Bend; 167 Galveston; 039 Brazoria; 071 Chambers; 291 Liberty; 339 Montgomery; 473 Waller ; other place FIPS are longer
tract = "*"
censuskey <- readLines(paste0(censusdir, "2017", "/key"))
#you have to get your own key - it's free, but private - put it wherever is convenient but not accessible to the public.
#https://api.census.gov/data/key_signup.html
#Notes on where I got the raw files
#census geometry files for 2010 (and earlier) lines were taken on 12/27/2019 from: https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.2017.html 
#and https://www.census.gov/geographies/mapping-files/time-series/geo/cartographic-boundary.html under the year (they changed the web interface), selecting the block group for Texas - but should work on other states, too. Put the unzipped files into the folder that matches the censusdir you set up.
geo_vintage <- "2021" #should be able to match vintage, depending on date.
source('BaseScripts/Census_Data.R') #this is just the helpers for accessing the U.S. Census api 
```
Only add later!!!

```{r get geometry files from census, include=FALSE}
#do on blocks, then just make tract id from geoid for blocks
censusblocks <- st_read(paste0(censusdir, geo_vintage, "/geo_census/cb_", geo_vintage, "_", state, "_bg_500k/cb_", geo_vintage, "_", state, "_bg_500k.shp"))
censusblocks <- as.data.table(st_transform(censusblocks, crs = 3857)) #for eventual merge with HCAD / 4326 for census
#have to make some decisions about how broad to go on some of the patterns.
#Counties around Houston: 201 Harris; 157 Fort Bend; 167 Galveston; 039 Brazoria; 071 Chambers; 291 Liberty; 339 Montgomery; 473 Waller - here we get only Harris.
#censusblocks <- censusblocks[COUNTYFP%in%c("201","157","167","039","071","291","339","473"),]
censusblocks <- censusblocks[COUNTYFP=="201",]
#some quick things for convenience - finding the centroid of each file.
censusblocks$geoid_centroid <- st_centroid(censusblocks$geometry)
```

```{css, echo=FALSE}
table {
  margin: auto;
  border-top: 1px solid #666;
  border-bottom: 1px solid #666;
}
table thead th { border-bottom: 1px solid #ddd; }
th, td { padding: 5px; }
thead, tfoot, tr:nth-child(even) { background: #eee; }
.striped tr:nth-child(even) { background: #eee; }
```

For the decennial 2020: https://www2.census.gov/programs-surveys/decennial/2020/technical-documentation/complete-tech-docs/summary-file/2020Census_PL94_171Redistricting_StatesTechDoc_English.pdf

```{r get decennial census data from census}
#for each county, can have sex_age by blck group - and thus pop by block group, too
block_race_data_from_census <- censusData_byGroupName(censusdir, vintage, state, censuskey, 
                       groupname = "P1",county_num = county,
                       block="block_group",api_type="dec/pl",path_suff="est.csv")

```

```{r look at only labels race}
block_race_data_DT <- as.data.table(block_race_data_from_census)
block_race_data_DT <- block_race_data_DT[order(label)]
kable(block_race_data_DT[1:20,1:2],caption = "Block group census data, race - Name and Label",table.attr = "class=\"striped\"", format = "html")
```

```{r look at only labels ethnicity}
block_ethnicity_data_from_census <- censusData_byGroupName(censusdir, vintage, state, censuskey, 
                       groupname = "P2",county_num = county,
                       block="block_group",api_type="dec/pl",path_suff="est.csv")
block_eth_data_DT <- as.data.table(block_ethnicity_data_from_census)
block_eth_data_DT <- block_eth_data_DT[order(label)]
kable(block_eth_data_DT[1:20,1:2],caption = "Block group census data ethnicity - Name and Label",table.attr = "class=\"striped\"", format = "html")
```

There are a number of things to talk about in terms of how the census is collected, and how they've decided on their various categories for race and ethnicity - both originally and in the development over time. For right now, I just want to point out how the census thinks about representing individuals in their geographical context. You can think of it as a pyramid, where each higher level of aggregation simply sums over the parts, or as a map where each larger section completely contains the smaller areas without losing the integrity of the boundary (i.e., it still adds up properly because it covers the same area and/or the same number of people). In this table, we only showed the name and the label - the concept (in this case, race) is meant to tie the tables to other tables and isn't relevant to the analyses within the table. The label, in some sense, is like the type for the number given in the column, each of which is a census block group. Just as the geoid encodes the embedding of the block group - i.e., 48 is the state, 201 is the county, the next six numbers are the tract and the final number is the block group - the label encodes the type of thing the number represents - it is a total number, with the population of either one or more races, with a designation made by the census for different racial categories. The idea is that as you add a characteristic to a person - either geographic location or race - you are also designating them as belonging to a subset of a larger population. With an appropriate schema, the subsets are complete and mutually exclusive, like the block groups adding into tracts, then counties (for most of the U.S.), and states. For geography, this requires some stipulations - you have to declare April 1st as the day of residence, for example, and do other things to account for transient populations, incarcerated people, and children with multiple guardians, for some obvious examples. The census largely deals with these edge cases behind the scenes and we start just with what they are making available. For the sake of calculations, the number of people in each category is given, with totals for the whole and each subset, so that percentages and other types of summary statistics can be calculated in whatever aggregations over geography and category are most relevant. That projection down to the individuals as unit from which other calculations are constructed is something we'll take advantage of, for example, in creating comparisons between different times, places, and categories used by the census in ways that make direct comparison difficult. 

Also, as we look at the two data sets, one organized by race, and the other by ethnicity, and we see that the ethnicity table includes all the race categories under "Not Hispanic or Latino," but no race categories for "Hispanic or Latino." Because we have the race categories, without reference to ethnicity, we can tell how many people are categorized as "Hispanic or Latino" by race, but it's not given directly in the category. The decision of how to represent yourself, which seemed to have been firmly in your hands as the person responding to the questions, was overridden by the way in which the table was constructed for those who answered that they were "Hispanic or Latino" and "Black or African American." Those decisions, of course, may have been downstream from other designations - if you had wanted to use "Latinx," for example, the census taker would have nodded in a friendly recognition, and then written down "Hispanic or Latino." 

Because we have both the geographic boundaries and the population numbers by census block group, we can combine them and look at the values.

First, some very quick tests to make sure we have consistent files.
```{r test consistency race and ethnicity}
#quick checks on the total population, as published by the census
#for census quickfacts, on Harris County: https://www.census.gov/quickfacts/harriscountytexas
sum(block_race_data_DT[name=="P1_001N",4:length(block_race_data_DT[1,])])==4731145
sum(block_eth_data_DT[name=="P2_001N",4:length(block_eth_data_DT[1,])])==4731145
```

```{r create demographic file with basic population numbers}
#test structure
block_race <- block_race_data_DT[!endsWith(label,":")] %>%
  pivot_longer(4:ncol(block_race_data_DT),names_to = "GEOID", values_to = "number") %>%
  mutate(label = str_remove_all(label,"!!Total:!!"),
         label = str_remove_all(label,"Population of one race:!!"),
         label = str_remove_all(label,"Population of two or more races:!!"),
         GEOID = str_remove_all(GEOID, "_")) %>%
  select(GEOID,label,number) %>%
  pivot_wider(names_from = label,values_from = number)
block_race <- as.data.table(block_race)
sum(block_race[,2:length(block_race[1,])])==sum(block_race_data_DT[name=="P1_001N",4:length(block_race_data_DT[1,])])
#uncount race
bg_population <- block_race_data_DT[!endsWith(label,":")] %>%
  pivot_longer(4:ncol(block_race_data_DT),names_to = "GEOID", values_to = "number") %>%
  mutate(label = str_remove_all(label,"!!Total:!!"),
         label = str_remove_all(label,"Population of two or more races:!!"),
         GEOID = str_remove_all(GEOID, "_")) %>%
  select(GEOID,label,number) %>% 
  separate(label, c("number_of_races","full_race"), sep = ":!!", remove = F, convert = FALSE) %>%
  mutate(includes_White = if_else(str_detect(full_race,"White"),T,F),
         includes_Black = if_else(str_detect(full_race,"Black"),T,F),
         includes_Asian = if_else(str_detect(full_race,"Asian"),T,F),
         includes_Some_Other = if_else(str_detect(full_race,"Some Other"),T,F),
         includes_AIAN = if_else(str_detect(full_race,"American Indian"),T,F),#American Indian and Alaska Native
         includes_Islands = if_else(str_detect(full_race,"Islander"),T,F)) %>%
  uncount(as.numeric(number),.id = "race_id")
      
nrow(block_population)==sum(block_race_data_DT[name=="P1_001N",4:length(block_race_data_DT[1,])])

#The ethnicity files are structured in a way that let's us match them
block_eth <- block_eth_data_DT[!endsWith(label,":")] %>%
  pivot_longer(4:ncol(block_eth_data_DT),names_to = "GEOID", values_to = "number") %>%
  mutate(label = str_remove_all(label,"!!Total:!!"),
         label = str_remove_all(label,"Not Hispanic or Latino:!!"),
         label = str_remove_all(label,"Population of one race:!!"),
         label = str_remove_all(label,"Population of two or more races:!!"),
         GEOID = str_remove_all(GEOID, "_")) %>%
  select(GEOID,label,number) %>%
  pivot_wider(names_from = label,values_from = number)
block_eth <- as.data.table(block_eth)
sum(block_eth[,2:length(block_eth[1,])])==sum(block_eth_data_DT[name=="P2_001N",4:length(block_eth_data_DT[1,])])

#uncount ethnicity 
block_eth_pop <- block_eth_data_DT[!endsWith(label,":")] %>%
  pivot_longer(4:ncol(block_eth_data_DT),names_to = "GEOID", values_to = "number") %>%
  mutate(label = str_remove_all(label,"!!Total:!!"),
         label = str_remove_all(label,"Not Hispanic or Latino:!!"),
         #label = str_remove_all(label,"Population of one race:!!"),
         label = str_remove_all(label,"Population of two or more races:!!"),
         GEOID = str_remove_all(GEOID, "_")) %>%
  select(GEOID,label,number) %>%
  separate(label, c("number_of_races","full_race"), sep = ":!!", remove = F, convert = FALSE) %>%
  mutate(includes_White = if_else(str_detect(full_race,"White"),T,F),
         includes_Black = if_else(str_detect(full_race,"Black"),T,F),
         includes_Asian = if_else(str_detect(full_race,"Asian"),T,F),
         includes_Some_Other = if_else(str_detect(full_race,"Some Other"),T,F),
         includes_AIAN = if_else(str_detect(full_race,"American Indian"),T,F),#American Indian and Alaska Native
         includes_Islands = if_else(str_detect(full_race,"Islander"),T,F)) %>%
  uncount(as.numeric(number),.id = "eth_id") 
  
nrow(block_eth_pop)==sum(block_eth_data_DT[name=="P2_001N",4:length(block_eth_data_DT[1,])])


#left merge on data.table; NAs become Hispanic; had technical difficulties with dplyr
bg_population <- as.data.table(bg_population)
bg_population[,("bg_race_id") := paste0(GEOID,number_of_races,includes_White,
                             includes_Black,includes_Asian,includes_Some_Other,
                             includes_AIAN,includes_Islands,
                             as.character(1000000+sample(1:.N))),
              by=.(GEOID,number_of_races,includes_White,
                             includes_Black,includes_Asian,includes_Some_Other,
                             includes_AIAN,includes_Islands)]
block_eth_pop <- as.data.table(block_eth_pop)
block_eth_pop[,("bg_race_id") := paste0(GEOID,number_of_races,includes_White,
                             includes_Black,includes_Asian,includes_Some_Other,
                             includes_AIAN,includes_Islands,
                             as.character(1000000+sample(1:.N))),
              by=.(GEOID,number_of_races,includes_White,
                             includes_Black,includes_Asian,includes_Some_Other,
                             includes_AIAN,includes_Islands)]

demog_pop <- bg_population[bg_demographic,on="bg_race_id"]
nrow(demog_pop[is.na(i.GEOID)]) == nrow(block_eth_pop[number_of_races=="Hispanic or Latino"])
demog_pop[,("Latino"):=if_else(is.na(i.GEOID),T,F)]
table(demog_pop$Latino)
#we now have how each person had their race characterized, as well as their ethnicity
#clean up
pop_demographic <- demog_pop[,c("GEOID","Latino","number_of_races","full_race",
                                     "includes_White","includes_Black",
                              "includes_Asian","includes_AIAN","includes_Islands",
                              "includes_Some_Other")]
```




```{r add to census geography file}
#and add to the maps of the censusblocks
#I like the way data.table does the merge, avoiding a shallow copy error
censusblocks_demographics <- censusblocks[pop_demographic,on = "GEOID"] 
rm(list = ls(pattern = "^block"))
```

Adding ethnicity and race together is difficult because the categories are constructed and implemented in different ways over time, and there are political considerations that drive how people characterize themselves - or have their designations over-ridden by the census takers [note].  

```{r plot block group population size across Harris}
censusblocks_demographics[,("pop_density_sq_km"):=round((Total/ALAND)*1000000)] #people per square kilometer
pop_density_Harris <- st_as_sf(censusblocks_demographics[!is.na(STATEFP),
                                      c("Total","pop_density_sq_km","GEOID","includes_White","includes_Black",
                                        "includes_Asian","includes_Some_Other",
                                        "geometry")],sf_column_name = "geometry")
pop_density_Harris <- st_transform(pop_density_Harris,crs = 4326)
st_write(pop_density_Harris,"~/Downloads/pop_density_Harris.geojson",driver="GeoJSON")
```

It's interesting that the population density is high at places where there are apartment complexes. Here's a [kepler.gl map](https://kepler.gl/demo/map?mapUrl=https://dl.dropboxusercontent.com/s/crph6k44lcudkmz/keplergl_wc5hg642.json)
Houston is still a largely segregated city, although housing segregation is not enforced by law. One immediate question is whether the decennial census will reflect that segregation in ways that help us understand important patterns in neighborhoods. 

#Add gender and ages from making_sam.Rmd









What we notice in the tables is that the subpopulations add up to the higher levels. When the groups don't match, we can project down to a lower unit (i.e., the individual at a certain time) and then try to re-assign individuals to positions within the spatial distribution. You can do that with the concept and label columns, as one tries to aggregate across the tables available from the census, but if the concepts don't match, it's like trying to line up cities with the tract data - sometimes the boundaries don't match. Cf. arguments in "Abstraction and Adjunction." Should also discuss the reconstruction attack - https://www.pnas.org/doi/10.1073/pnas.2218605120

But more importantly, there's what the mathematicians call an adjunction at work between the production and the construction - placing something in an order and creating a space within which that production can happen - where the movement from the top down in the order of the geography is, at every intersection, embedded in the higher level, and where the social determinants are not embedded in the same way. The difference in the embeddings produces effects that allow us to understand the distributions at other levels and to find the characteristic functions that relate the various elements and layers. We need to take this in a couple of steps, though.

```{r make geojson map 2020 census}

```

First, what is a context in this case? It's the frame that makes it possible to coherently make sense of the transformations between levels. When we say that we understand a point in terms of the surrounding points, we're transforming the context to a single point, but that's not the only example. When we say that the population should be understood in terms of population density by area, or by percentage of the total population, or by percentage of the population that is white, etc., we're constraining one layer of explanation in a way that makes the individual appear as meaningful because of that constraint.

How does that teach us about strengths? Strengths are overcoming constraints / barriers? Power is imposing constraints, or creating a situation where a response has to happen within a certain framework. (this is to be understood algebraically and not arithmetically). The framing creates an order - a poset or a toset is easy to see, but more broadly, any way that things can be ordered - well-ordering theorem and the axiom of choice.

What's it mean for "number" to be the context? A set of rules for combining, etc - i.e., a category. But then one should think about how categories are added, and not just things that have already been translated into number. The symmetric monoidal category as the unit - initial object, etc. Note on why that breaks with set theory?

Still want to move toward the idea that functor is the right way to see the mapping between individuals as capacity grows, and that adjunction is the right way to understand what the right space from which good development emerges.

```{r test for ACS vs Decennial 2020}
bg_sex_by_age_race_data_from_acs_20 <- 
          censusData_byGroupName(censusdir, vintage, state, censuskey, 
                                 groupname = "B01001",county_num = "201",
                                 block="block_group",api_type="acs/acs5",path_suff="est.csv")
#compare with totals for censusblocks
#looks like right total, but the blocks have very large different numbers per block.
bg_dt <- as.data.table(bg_sex_by_age_race_data_from_acs_20)
sum(bg_dt[name=="B01001_001E",4:2833])
#[1] 4680609
bg_sex_by_age_race_data_from_acs_20_error <- 
          censusData_byGroupName(censusdir, vintage, state, censuskey, 
                                 groupname = "B01001",county_num = "201",
                                 block="block_group",api_type="acs/acs5",path_suff="err.csv")
bg_err_dt <- as.data.table(bg_sex_by_age_race_data_from_acs_20_error)
sum(bg_err_dt[name=="B01001_001M",as.numeric(4:2833)])
#[1] 4014355

tr_sex_by_age_race_data_from_acs_20 <- 
          censusData_byGroupName(censusdir, vintage, state, censuskey, 
                                 groupname = "B01001",county_num = "201",
                                 block="tract",api_type="acs/acs5",path_suff="est.csv")
```