---
title: "Making Sam"
author: "Dan Price"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
geometry: margin=1in
fontsize: 11pt
documentclass: article
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source('~/Documents/Projects/SyntheticDataSet/BaseScripts/Census_Data.R')
source('~/Documents/Projects/SyntheticDataSet/workflow.R')
censuskey <- readLines(paste0(censusdir, "2017", "/key"))
```
## Preliminaries -- very broad

Plan: find smallest units of space combined from 2010 census
https://www2.census.gov/programs-surveys/decennial/2010/technical-documentation/complete-tech-docs/summary-file/sf1.pdf
Gives a nice place to look - P1, P5, P6, P8 - look at each and discuss briefly.

Let's begin with PCT12, which is tract level data but has every age by year, gender, ethnicity and race. It has 101 possible age groups, with 1-99 years and then one for "100 to 104 years" and one for "105 to 109 years". It then has categories for all the built in race and ethnicity categories, with each person counted in the total, and every person categorized by race (there are tables for how many people had to have a race assigned, given they refused to provide, but everyone has an assigned race); Hispanic is a problematic category for counting, as well as for historical reasons, and is dealt with differently in the decennial and ACS reporting. Let's download it, do some quick checks, and then look at it.  

```{r look at PCT12}
#this gives you by every year at the tract level - could be a good example for adding together - PCTs never go below tract level
    dec_sex_by_age_tract_data_from_census_10 <- censusData_byGroupName(censusdir, vintage="2010", state, censuskey, 
                                                                              groupname = "PCT12",county_num = "201",
                                                                              block="tract",api_type="dec/sf1",path_suff="est.csv")

```
Show how some of the testing works
```{r test for na}
    dec_SAR_data_from_census_10 <- as.data.table(dec_sex_by_age_tract_data_from_census_10)
    percent_na <- dec_SAR_data_from_census_10[,sum(is.na(.SD))] / 
      (dec_SAR_data_from_census_10[,sum(!is.na(.SD))]+dec_SAR_data_from_census_10[,sum(is.na(.SD))])
    paste("Percentage of NAs in file:",as.integer(100*percent_na))
```

Need to check to make sure that their totals at least add up - every so often the census makes mistakes that we need to clean up in some way. This lets us see that we need to check. We had the whole state, so for our case going down to county first
```{r check for consistency on totals}
    dec_SAR_Harris_data_from_census_10 <- dec_SAR_data_from_census_10 %>%
      select(name,label,concept,starts_with("48201"))
#needs to be numeric for the sum in the test
    dec_SAR_Harris_data_from_census_10[,4:ncol(dec_SAR_Harris_data_from_census_10)] <- dec_SAR_Harris_data_from_census_10[,lapply(.SD[,4:ncol(dec_SAR_Harris_data_from_census_10)], as.numeric)]
#there's a total for each concept and for the whole, but in the ones without a total, there are also total female and male.
test <- colSums(dec_SAR_Harris_data_from_census_10[label=="Total",4:ncol(dec_SAR_Harris_data_from_census_10)])*2 ==
      colSums(dec_SAR_Harris_data_from_census_10[label!="Total",4:ncol(dec_SAR_Harris_data_from_census_10)])
#see if any of the tests don't match; if false, need to go back and check on what happened
length(test[test==F])==0
```



could be interesting to just show how that casting works from every year to the groups
```{r block_group sex by age}
dec_bgSAR_data_from_census_10 <- censusData_byGroupName(censusdir, vintage="2010", state, censuskey, 
                                                                      groupname = "P12",county_num = "201",
                                                                      block="block_group",api_type="dec/sf1",path_suff="est.csv")
```

should show the testing and the questions
```{r demography test problems}
#point is that you can't do the test on whether totals equal because you have to remove White Alone not Hispanic or Latino and Hispanic or Latino
#needs to be numeric for the sum in the test
dec_bgSAR_data_10 <- as.data.table(dec_bgSAR_data_from_census_10)
    dec_bgSAR_data_10[,4:ncol(dec_bgSAR_data_10)] <- dec_bgSAR_data_10[,lapply(.SD[,4:ncol(dec_bgSAR_data_10)], as.numeric)]
#there's a total for each concept and for the whole, but in the ones without a total, there are also total female and male.
test <- colSums(dec_bgSAR_data_10[label=="Total",4:ncol(dec_bgSAR_data_10)])*2 ==
      colSums(dec_bgSAR_data_10[label!="Total",4:ncol(dec_bgSAR_data_10)])
#see if any of the tests don't match; if false, need to go back and check on what happened
length(test[test==F])==0
```

For the next step, we need to transform the counts we have for demography so that each person is represented as having properties, including geography and demography. Some notes about how this works more abstractly, or maybe add that later...
Let's take the tract-level data, as the most specific for year and race category, and then add the block_group information because that gives us important geographic differences. We'll work with only Harris County at this point.
First, we need to identify the rows which, if added together, give us a complete and non-repeating set of the population. There is one way to do that with the overall total row, with the two gender total rows, and with all of the individual age rows without the totals. Unfortunately, the census reports have a somewhat idiosyncratic way of reporting the data, and the way to identify these rows is not always simple. This case is relatively easy, and a good example to start with. The "label" column has three components, separated by double exclamation points. (They made changes in the way the separations work in 2019, so these small scripts will have to be modified for later years. The decennial and ACS also have small differences that have to be accounted for, as we will see.)
We can use a little trick because of how the R library dyplyr performs the translation and expansion of the representation, so that we're looking at rows of people with geographic and demographic properties and not rows of categories against columns of geography. We will get a warning that NAs were introduced by coercion, but it happens that those will be the rows that we want to exclude in any case.

```{r expand SARE}
    dec_SARE_Harris_10 <- dec_SAR_Harris_data_from_census_10 %>%
      pivot_longer(4:ncol(dec_SAR_Harris_data_from_census_10),names_to = "tract", values_to = "number_sams",
                   names_transform = list(tract=as.character)) %>%
      separate(label, c("total","sex","age"), sep = "!!", remove = F, convert = FALSE) %>%
      mutate(re_code = substr(name,7,7),
             race = str_replace(concept,"SEX BY AGE \\(",""),
             race = str_replace(race,"\\)",""),
             age = str_replace(age, "Under 1 year", "0"),
             age = str_replace(age,"year"," year"),
             age = as.integer(substr(age,1,3))
             ) %>%
      filter(number_sams > 0, !is.na(age))
```

Once we have the file for the entire population, we'll want to make a complete population with ethnicity and one with race.
Doing race first

```{r expand SAR}
    #setup race codes https://www.census.gov/programs-surveys/acs/guidance/which-data-tool/table-ids-explained.html
    race_codes <- c("A","B","C","D","E","F","G")
    dec_SAR_Harris_10 <- dec_SARE_Harris_10 %>%
      filter(re_code %in% race_codes) %>%
      uncount(number_sams,.id = "sams_race_id") #will create different id later
```
(put in something that prints a total pop?)

And then one for ethnicity:

```{r expand SAE}
    #one for Hispanic and then not Hispanic or Latino for each race; H and I do not match race codes in ACS
    ethnicity_codes <- c("H","I","J","K","L","M","N","O") 
    dec_SAE_Harris_10 <- dec_SARE_Harris_10 %>%
      mutate(race=str_replace(race,", NOT HISPANIC OR LATINO","")) %>%
      filter(re_code %in% ethnicity_codes) %>%
      uncount(number_sams,.id = "sams_ethnicity_id") #will create different id later
```
Can do some tests on them, but both get a total of 4092459, which is about 15,000 short of published...
Group quarters?

Talk a little bit about how it doesn't work to just give every White person a 40% chance of also being Hispanic or Latino....
At some point, will also want to talk about using data.table vs. dyplyr / tidyr and what, in general one is looking for in rows, columns, and vectors, etc.

What we do, instead, is to order each of the sets by their shared characteristics and assign an id, with numbers assigned sequentially for rows that match on all characteristics. 

```{r join SAE and SAR}
dec_SAR_Harris_10 <- as.data.table(dec_SAR_Harris_10)
dec_SAE_Harris_10 <- as.data.table(dec_SAE_Harris_10)
dec_SAR_Harris_10[,("sar_match_id"):=
                    paste0(tract,sex,age,race,as.character(100000+seq.int(1:.N))),
                  by=.(tract,sex,age,race)]
dec_SAE_Harris_10[,("sar_match_id"):=
                    paste0(tract,sex,age,race,as.character(100000+seq.int(1:.N))),
                  by=.(tract,sex,age,race)]
dec_SAR_Harris_10[,("ethnicity"):=
                    dec_SAE_Harris_10[.SD, list(re_code), on = .(sar_match_id)]]
#then add a marker to dec_SAE_Harris_10 that those individuals are already represented in SAR
dec_SAE_Harris_10[,("race2"):=
                    dec_SAR_Harris_10[.SD, list(re_code), on = .(sar_match_id)]]
#the ones that don't match are the ones that are Hispanic
dec_SAR_Harris_10[is.na(ethnicity),("sar_match1_id"):=
                    paste0(tract,sex,age,as.character(100000+seq.int(1:.N))),
                  by=.(tract,sex,age)]
dec_SAE_Harris_10[is.na(race2),("sar_match1_id"):=
                    paste0(tract,sex,age,as.character(100000+seq.int(1:.N))),
                  by=.(tract,sex,age)]
dec_SAR_Harris_10[is.na(ethnicity),("ethnicity"):=
                    dec_SAE_Harris_10[.SD, list(re_code), on = .(sar_match1_id)]]
dec_SAE_Harris_10[is.na(race2),("race2"):=
                    dec_SAR_Harris_10[.SD, list(re_code), on = .(sar_match1_id)]]

```

Do some tests

```{r SAE SAR join tests}

```

Don't forget to add ages for those over 100
Want to make it a smooth function, so figure out how many are over 104, then divide that by 5, and divide 100-104 by 5, then use that as the slope
```{r expand bgSAR}
dec_bgSARE_10 <- dec_bgSAR_data_10 %>%
  pivot_longer(4:ncol(dec_bgSAR_data_10),names_to = "geoid", values_to = "number_sams",
                   names_transform = list(geoid=as.character)) %>%
      separate(label, c("total","sex","age_range"), sep = "!!", remove = F, convert = FALSE) %>%
      mutate(re_code = substr(name,5,5),
             race = str_replace(concept,"SEX BY AGE \\(",""),
             race = str_replace(race,"\\)",""),
             age_range = str_replace(age_range,"Under 5 years","0  to  4 years"), #have to regularize and make possible to compare
             age_range = str_replace(age_range,"5 to 9 years","05 to  9 years"),
             age_range = str_replace(age_range,"18 and 19 years","18 to 19 years"),
             age_range = str_replace(age_range,"20 years","20 to 20 years"),
             age_range = str_replace(age_range,"21 years","21 to 21 years"),
             age_range = str_replace(age_range,"85 years and over","85 to 94 years"),  #have to skew left when assigning.
             first_age = as.numeric(substr(age_range,1,2)),
             last_age = as.numeric(substr(age_range,7,8)),
             tract = str_remove_all(geoid,"_"),
             tract = substr(tract,1,11)
             ) %>%
      filter(number_sams > 0, !is.na(age_range))
```

```{r SAR expand to bg}
    race_codes <- c("A","B","C","D","E","F","G")
    dec_bgSAR_10 <- dec_bgSARE_10 %>%
      filter(re_code %in% race_codes) %>%
      uncount(number_sams,.id = "sams_race_id")
```

should put in ethnicity codes for bgSAE and join, so that they get the match as far as possible, even if we don't know all the specifics...
```{r SAE expand to bg}
    eth_codes <- c("H","I")
    dec_bgSAE_10 <- dec_bgSARE_10 %>%
      filter(re_code %in% eth_codes) %>%
      uncount(number_sams,.id = "sams_race_id")
```

https://www2.census.gov/programs-surveys/decennial/2010/technical-documentation/complete-tech-docs/summary-file/sf1.pdf
put in households
add P15, then other hh stuff that can be added without problems, then add people in
P21 should also be good; p29, p30...

have to think about how family info is different from hh

group quarters are needed b/c hh don't include them
```{r group quarters to add}
dec_group_quarters_block_data_from_census_20 <- censusData_byGroupName(censusdir, vintage="2020", state, censuskey, 
                                                                       groupname = "P5",county_num = "201",
                                                                       block="block_group",api_type="dec/pl",path_suff="est.csv")
```



expand from census

rearrange so that they all add to same whole and then figure out how to distribute them among that space

tests of each step

discussion of power sets vs. categories? 

redoing HCAD first to help with generation of 2011 - a space to move into...


