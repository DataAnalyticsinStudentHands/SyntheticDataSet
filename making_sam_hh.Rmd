---
title: "Making Sam Households"
author: "Dan Price"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
geometry: margin=1in
fontsize: 11pt
documentclass: article
header-includes: 
  - \usepackage{tikz}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Preliminaries -- very broad
```{r prelims}
source('~/Documents/Projects/SyntheticDataSet/BaseScripts/Census_Data.R')
library(tidyr)
library(dplyr)
library(stringr)
library(data.table)
#maindir = "~/University Of Houston/Price, Daniel M - Social Network Hypergraphs/"
maindir = "~/Downloads/UH_OneDrive/OneDrive\ -\ University\ Of\ Houston/Social\ Network\ Hypergraphs/" #Dan at home
#maindir = "~/Downloads/OneDrive\ -\ University\ Of\ Houston/Social\ Network\ Hypergraphs/" #Dan at work
housingdir = paste0(maindir,"HCAD/")
houstondatadir = paste0(maindir,"HoustonCityData/") 
censusdir = paste0(maindir,"Census/") 
vintage = "2019"
housingStockFromRDS = TRUE 
#numberOfCores = 1
state = 48 #48 Texas; 22 Louisiana
county = 201 #8 county region: 201 Harris; 157 Fort Bend; 167 Galveston; 039 Brazoria; 071 Chambers; 291 Liberty; 339 Montgomery; 473 Waller ; other place FIPS are longer
tract = "*"
Sam_seed = 135
#you don't need a censuskey if you're not pulling new files down; you can only use this one if you have correct access to the OneDrive
censuskey <- readLines(paste0(censusdir, "2017", "/key"))
```


For new file, and need a bit of a preamble

We're going to begin with the 2010 block group data table, P28 - Householdtype by Household Size by Race and Ethnicity. We start here not because it provides the greatest granularity, although it is by block group, but because it has the best structured relationality, around which commutative triangles can be built. The longer idea is to see the census bureau's copy of the full data representation as being both perfectly commutable in the ways it can be represented and granular at an individual level (again, setting aside difficulties with their collection and category choice). There are then ways in which the census bureau produces tables, with different concerns at different stages and with different products, but they both try to ensure the structure of commutability is maintained within the particular representation and to ensure that the people interpreting the data understand how it relates statistically as a subset - which is to say, how the granularity of the presentation is related to the underlying granularity as the chance that when you see someone from a particular subset, they fit into the demographics of the larger group. [that could be better phrased, but trying to get at difference between set theory and type theory with the categorical spin]

Let's download P28 and look at it.

```{r download hhtype hhsize race eth bg}
dec_bgHH_type_size_re_data_from_census_10 <- 
  censusData_byGroupName(censusdir, vintage="2010", state, censuskey, 
                         groupname = "P28",county_num = "201",
                         block="block_group",api_type="dec/sf1",path_suff="est.csv")
```

Then do our basic checks:
```{r hh_type_size_re test problems}
dec_bgHH_data_10 <- as.data.table(dec_bgHH_type_size_re_data_from_census_10)
    percent_na <- dec_bgHH_data_10[,sum(is.na(.SD))] / 
      (dec_bgHH_data_10[,sum(!is.na(.SD))]+dec_bgHH_data_10[,sum(is.na(.SD))])
    paste("Percentage of NAs in file:",as.integer(100*percent_na))
#make the numbers into numeric type - some operations won't work with either integer or character, although we could play with optimizing it
    dec_bgHH_data_10[,4:ncol(dec_bgHH_data_10)] <- dec_bgHH_data_10[,lapply(.SD[,4:ncol(dec_bgHH_data_10)], as.numeric)]
#multiplying the side labeled only "Total" by 2:
test <- colSums(dec_bgHH_data_10[label=="Total",4:ncol(dec_bgHH_data_10)])*2 ==
      colSums(dec_bgHH_data_10[label!="Total",4:ncol(dec_bgHH_data_10)])
#see if any of the tests don't match; if false, need to go back and check on what happened
length(test[test==F])==0
hh_totals_bg <- dec_bgHH_data_10[label=="Total"&concept=="HOUSEHOLD TYPE BY HOUSEHOLD SIZE",4:ncol(dec_bgHH_data_10)]
paste0("Number of Households total for Harris County by block_group: ", sum(hh_totals_bg[,]))
```

Now we need to convert the census representation into a representation of individual households.

```{r expand P28 into dec_bgHH_10}
    race_codes <- c("A","B","C","D","E","F","G")
    dec_bgHHr_10 <- dec_bgHH_data_10 %>%
      mutate(
        race = substr(name,5,5),
        label = str_remove_all(label,"Total!!")) %>%
      filter(label != "Total") %>% #keep only the ones that aren't aggregated
      pivot_longer(4:ncol(dec_bgHH_data_10),names_to = "geoid", values_to = "number_sams") %>% 
      separate(label, c("family","hh_size"), sep = "!!", remove = F, convert = FALSE) %>%
      filter(!is.na(hh_size) & race%in%race_codes) %>% #to get rid of aggregations by family
      uncount(number_sams,.id = "hhr_size_id",.remove = TRUE) 
    dec_bgHHr_10 <- as.data.table(dec_bgHHr_10) #dyplyr had stripped it of dt
    paste0("Number of households in file: ", nrow(dec_bgHHr_10))
    #break into race and ethnicity files
    nrow(dec_bgHHr_10)==sum(hh_totals_bg[,])
    #and same for ethnicity
    dec_bgHHe_10 <- dec_bgHH_data_10 %>%
      mutate(
        ethnicity = substr(name,5,5),
        label = str_remove_all(label,"Total!!")) %>%
      filter(label != "Total") %>% #keep only the ones that aren't aggregated
      pivot_longer(4:ncol(dec_bgHH_data_10),names_to = "geoid", values_to = "number_sams") %>% 
      separate(label, c("family","hh_size"), sep = "!!", remove = F, convert = FALSE) %>%
      filter(!is.na(hh_size) & ethnicity%in%c("H","I")) %>% 
      uncount(number_sams,.id = "hhe_size_id",.remove = TRUE) 
    dec_bgHHr_10 <- as.data.table(dec_bgHHr_10) #dyplyr had stripped it of dt
    paste0("Number of households with ethnicity attributes in file: ", nrow(dec_bgHHe_10))
    #should clean up
    rm(dec_bgHH_data_10)
    rm(dec_bgHH_type_size_re_data_from_census_10)
```


Now let's get P17, average household size by age (with people under 18 in household or not) and race and ethnicity by block group. It adds the question of what happens with other sorts of representations besides summation or subset, with average being easy to understand and important to the underlying idea of maintaining structure. The additional information is a hint about how households with people under 18 differ from those without, by race and ethnicity. Since there is also a total, which we can generate separately from the dec_bgHHr_10 file we can check our process as well as give further shape to the representation for the two age groups.  

```{r download avg hhsize race eth bg}
dec_bgHH_avg_size_re_data_from_census_10 <- 
  censusData_byGroupName(censusdir, vintage="2010", state, censuskey, 
                         groupname = "P17",county_num = "201",
                         block="block_group",api_type="dec/sf1",path_suff="est.csv")
```
Then do our basic checks:
```{r hh_avg_size_re test problems}
dec_bgHH_avg_size_data_10 <- as.data.table(dec_bgHH_avg_size_re_data_from_census_10)
    percent_na <- dec_bgHH_avg_size_data_10[,sum(is.na(.SD))] / 
      (dec_bgHH_avg_size_data_10[,sum(!is.na(.SD))]+dec_bgHH_avg_size_data_10[,sum(is.na(.SD))])
    paste("Percentage of NAs in file:",as.integer(100*percent_na))
#make the numbers into numeric type - some operations won't work with either integer or character, although we could play with optimizing it
    dec_bgHH_avg_size_data_10[,4:ncol(dec_bgHH_avg_size_data_10)] <- dec_bgHH_avg_size_data_10[,lapply(.SD[,4:ncol(dec_bgHH_avg_size_data_10)], as.numeric)]
#multiplying the side labeled only "Total" by 2:
pop_avgs_bg <- dec_bgHH_avg_size_data_10[label=="Average household size!!Total"&concept=="AVERAGE HOUSEHOLD SIZE BY AGE",4:ncol(dec_bgHH_avg_size_data_10)]
paste0("Average family size for Harris County: ", mean(colMeans(pop_avgs_bg[,]))) # sum(pop_avgs_bg[,])/ncol(pop_avgs_bg) #to remember colMeans
#There is considerable variation at the block_group level
paste0("Minimum average family size for Harris County block groups: ",min(pop_avgs_bg[,]))
paste0("Maximum average family size for Harris County block groups: ",min(pop_avgs_bg[,])) 
paste0("Standard deviation for average family size for Harris County block groups: ",sd(pop_avgs_bg[,]))
```
[[should look at avg hh size by tenure, too- H16, along with other rent_own info]]
Looking at P17, we ask whether we should think about how one retains the structure of the average. Our strategy will be to order each hh as either above or below the average - since they are distributed into a set number of places afterward, we don't need to approximate a normal distribution or anything. 
Now we'll expand it into the average number of households by both race and ethnicity, for households with and without people under 18 in them, for each block_group. 
```{r expand P17 into dec_bgHH_avg_size_data_10}
    race_codes <- c("A","B","C","D","E","F","G")
    dec_bgHH_avg_size_r_10 <- dec_bgHH_avg_size_data_10 %>%
      mutate(
        race = substr(name,5,5)) %>%
      filter(label != "Average household size!!Total") %>% #keep only the ones that aren't aggregated
      filter(race%in%race_codes)  
    dec_bgHH_avg_size_r_10 <- as.data.table(dec_bgHH_avg_size_r_10) #dyplyr had stripped it of dt
    #and same for ethnicity
    dec_bgHH_avg_size_e_10 <- dec_bgHH_avg_size_data_10 %>%
      mutate(
        ethnicity = substr(name,5,5)) %>%
      filter(label != "Average household size!!Total") %>% 
      filter(ethnicity%in%c("H","I")) 
    dec_bgHH_avg_size_e_10 <- as.data.table(dec_bgHH_avg_size_e_10) 
    #should clean up
    rm(dec_bgHH_avg_size_data_10)
    rm(dec_bgHH_avg_size_re_data_from_census_10)
```

We'll eventually want to join this with P18, household type by race and ethnicity, before joining both back. The averages is P17 should match calculations in P28, from above. Can check those, first. If same, we can use it to check our process. 

```{r compare P17 dec_bgHH_avg_size avg to P28 dec_bgHH avg}
  dec_bgHHr_10[,("hh_size_n"):=as.numeric(substr(hh_size,1,1))]
  dec_bgHHr_10[,("avg_hh_size_bg"):=round(mean(hh_size_n),2),by=.(geoid)]
  test <- dec_bgHH_avg_size_data_10[label=="Average household size!!Total"&
            concept=="AVERAGE HOUSEHOLD SIZE BY AGE",4:ncol(dec_bgHH_avg_size_data_10)] == 
    dec_bgHHr_10[,avg_hh_size]
  dec_bgHHr_10[,("avg_hh_size_bg_r"):=round(mean(hh_size_n),2),by=.(geoid,race)]
  length(test[test==F])==0
  test <- dec_bgHH_avg_size_data_10[label=="Average household size!!Total"&
            concept=="AVERAGE HOUSEHOLD SIZE BY AGE (WHITE ALONE HOUSEHOLDER)",
            4:ncol(dec_bgHH_avg_size_data_10)] == 
    dec_bgHHr_10[race=="A",avg_hh_size_bg_r]
  length(test[test==F])==0
  dec_bgHHe_10[,("hh_size_n"):=as.numeric(substr(hh_size,1,1))]
  dec_bgHHe_10[,("avg_hh_size_bg_e"):=round(mean(hh_size_n),2),by=.(geoid,ethnicity)]
  test <- dec_bgHH_avg_size_data_10[label=="Average household size!!Total"&
            concept=="AVERAGE HOUSEHOLD SIZE BY AGE (WHITE ALONE HOUSEHOLDER)",
            4:ncol(dec_bgHH_avg_size_data_10)] == 
    dec_bgHHr_10[ethnicity=="I",avg_hh_size_bg_e]
  length(test[test==F])==0
```

plan:
make copy of dec_bgHHr_10 and dec_bgHHe_10 with avgs 
check type on orig_id
dec_copy[orig_id>.N/2,("rank_4_size"):=avg_hh_size_n+sample(.000001:(.N/10000),.N),by=.(geoid,race)] #should be a normal distribution - check how "order" works with ties? 
have to do it for each race, creating a match ID that doesn't have race in it, and is just assigning a seq.int based on .N on the sorted input.
matches puts in from ordered vector of sizes available for the group that includes all the races (works trivially for just that one). 
test will be tables by hh_size and hh_size by race/eth

if that works, 
do the same for under 18 and over 18 households - but for that, we need to know how many fit in each...
Using P19, P20, and P21, we should be able to shape P18 - moving each avg into dec_copy, too. - should be close on conserving avg. and distribution in categories
and check that against P28 or not.

Use H16 for Tenure by HH_size by race and ethnicity

Now let's get P18, household type by race and ethnicity, which has more detail in the type of household.
```{r download hhtype hhsize race eth bg}
dec_bgHH_type_re_data_from_census_10 <- 
  censusData_byGroupName(censusdir, vintage="2010", state, censuskey, 
                         groupname = "P18",county_num = "201",
                         block="block_group",api_type="dec/sf1",path_suff="est.csv")
```

Then do our basic checks:
```{r hh_type_re test problems}
dec_bgHH_type_data_10 <- as.data.table(dec_bgHH_type_re_data_from_census_10)
    percent_na <- dec_bgHH_type_data_10[,sum(is.na(.SD))] / 
      (dec_bgHH_type_data_10[,sum(!is.na(.SD))]+dec_bgHH_type_data_10[,sum(is.na(.SD))])
    paste("Percentage of NAs in file:",as.integer(100*percent_na))
#make the numbers into numeric type - some operations won't work with either integer or character, although we could play with optimizing it
    dec_bgHH_type_data_10[,4:ncol(dec_bgHH_type_data_10)] <- dec_bgHH_type_data_10[,lapply(.SD[,4:ncol(dec_bgHH_type_data_10)], as.numeric)]
pop_totals_bg <- dec_bgHH_type_data_10[label=="Total"&concept=="HOUSEHOLD TYPE",4:ncol(dec_bgHH_type_data_10)]
paste0("Number of Households total for Harris County by block_group: ", sum(pop_totals_bg[,]))
sum(pop_totals_bg[,])==nrow(dec_bgHHr_10)
```

Then expand into the representation of individual households by both ethnicity and race.
```{r expand P18 into dec_bgHH_type_10}
#break into race and ethnicity files
    race_codes <- c("A","B","C","D","E","F","G")
    dec_bgHHr_type_10 <- dec_bgHH_type_data_10 %>%
      pivot_longer(4:ncol(dec_bgHH_type_data_10),names_to = "geoid", values_to = "number_sams") %>% 
      mutate(
        race = substr(name,5,5),
        label = str_remove_all(label,"Total!!"),
        label = str_remove_all(label,"!!Other family")) %>%
      filter(label != "Total") %>% #keep only the ones that aren't aggregated
      separate(label, c("family","family_details"), sep = "!!", remove = F, convert = FALSE) %>%
      filter(!is.na(family_details) & race%in%race_codes) %>% #to get rid of aggregations by family
      uncount(number_sams,.id = "hhr_type_id",.remove = TRUE) 
    dec_bgHHr_type_10 <- as.data.table(dec_bgHHr_type_10) #dyplyr had stripped it of dt
    paste0("Number of households in file: ", nrow(dec_bgHHr_type_10))
    nrow(dec_bgHHr_10)==nrow(dec_bgHHr_type_10)
    
    #multiplying the side labeled only "Total" by 2:
    dec_bgHHr_type_10[,4:ncol(dec_bgHHr_type_10)] <- dec_bgHHr_type_10[,lapply(.SD[,4:ncol(dec_bgHHr_type_10)], as.numeric)]
    #and same for ethnicity
    dec_bgHHe_type_10 <- dec_bgHH_type_data_10 %>%
      mutate(
        ethnicity = substr(name,5,5),
        label = str_remove_all(label,"Total!!"),
        label = str_remove_all(label,"!!Other family")) %>%
      filter(label != "Total") %>% #keep only the ones that aren't aggregated
      pivot_longer(4:ncol(dec_bgHH_type_data_10),names_to = "geoid", values_to = "number_sams") %>% 
      separate(label, c("family","family_details"), sep = "!!", remove = F, convert = FALSE) %>%
      filter(!is.na(family_details) & ethnicity%in%c("H","I")) %>% 
      uncount(number_sams,.id = "hhe_type_id",.remove = TRUE) 
    dec_bgHHe_type_10 <- as.data.table(dec_bgHHe_type_10) #dyplyr had stripped it of dt
    paste0("Number of households with ethnicity attributes in file: ", nrow(dec_bgHHe_10))
    nrow(dec_bgHHe_10)==nrow(dec_bgHHe_type_10)
    #should clean up
    rm(dec_bgHH_type_data_10)
    rm(dec_bgHH_type_re_data_from_census_10)
```

Then do P22, HOUSEHOLD TYPE BY AGE OF HOUSEHOLDER, but which doesn't have race/eth
(how does that relate to P17? look at totals)

```{r basic household data download}
#block - sf1 - P15 and P16 (eth and race of hh) P18 (hhtype by race/eth) P22 (hhtype by age of hh) p28 (hhtype by hhsize by race/eth)
#plan - looks like P17 and P18 have much more detail than P28, so combine P17 with P28, then P18 with P28xP17
#then combine P16 with P28xP17xP18 and P15 with P28xP17xP18xP16   

#tract - sf2 - (Tenure by hhtype by age of hh - HCT9) - more age_groups and has tenure
```

```{r hh_relation download block}

dec_hh_relation_data_from_census_10 <- censusData_byGroupName(censusdir, vintage="2010", state, censuskey, 
                                                                groupname = "P29",county_num = "201",
                                                                block="block_group",api_type="dec/sf1",path_suff="est.csv")
```



The redistricting data collected in 2010 reports population estimates in yet a different format. It has one table that has races and ethnicity data for everyone over 18 and one that has it for everyone, with no ages attached. The race data gives more details on the composition of "Two or More Races" but nothing else new. The ethnicity file gives block level data for Hispanic or Latino who don't identify as White. Gives slightly more contour, but not much, and risks big differences on age and ethnicity or race per block group. (Although some contour is better than none!)

```{r pl data downloaded}
    dec_eth_block_data_from_census_10 <- censusData_byGroupName(censusdir, vintage="2010", state, censuskey, 
                                                                      groupname = "P2",county_num = "201",
                                                                      block="block_group",api_type="dec/pl",path_suff="est.csv")
    dec_race_block_data_from_census_10 <- censusData_byGroupName(censusdir, vintage="2010", state, censuskey, 
                                                                groupname = "P1",county_num = "201",
                                                                block="block_group",api_type="dec/pl",path_suff="est.csv")
    dec_eth_over18_block_data_from_census_10 <- censusData_byGroupName(censusdir, vintage="2010", state, censuskey, 
                                                                      groupname = "P4",county_num = "201",
                                                                      block="block_group",api_type="dec/pl",path_suff="est.csv")
    dec_race_over18_block_data_from_census_10 <- censusData_byGroupName(censusdir, vintage="2010", state, censuskey, 
                                                                groupname = "P3",county_num = "201",
                                                                block="block_group",api_type="dec/pl",path_suff="est.csv")
 
    
```




Then have the tract level details join into the bg representation? Should discuss whether to start with the household stuff - check if it has the PCT level of detail on ethnicity anywhere... 
If not, can just save the demographic_bg to the OneDrive and start from there.




https://www2.census.gov/programs-surveys/decennial/2010/technical-documentation/complete-tech-docs/summary-file/sf1.pdf
put in households
add P15 or P16, then other hh stuff that can be added without problems, then add people in
also look at H9
P21 should also be good; p29, p30...

have to think about how family info is different from hh

group quarters are needed b/c hh don't include them
```{r group quarters to add}
dec_group_quarters_block_data_from_census_10 <- 
  censusData_byGroupName(censusdir, vintage="2010", state, censuskey, 
                         groupname = "P5",county_num = "201",
                         block="block_group",api_type="dec/pl",path_suff="est.csv")
```



expand from census

rearrange so that they all add to same whole and then figure out how to distribute them among that space

tests of each step

discussion of power sets vs. categories? 

redoing HCAD first to help with generation of 2011 - a space to move into...


