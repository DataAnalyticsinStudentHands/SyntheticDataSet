---
title: "Making Sam Households"
author: "Dan Price"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
geometry: margin=1in
fontsize: 11pt
documentclass: article
header-includes: 
  - \usepackage{tikz}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Preliminaries -- very broad
```{r prelims}
source('~/Documents/Projects/SyntheticDataSet/BaseScripts/Census_Data.R')
library(tidyr)
library(dplyr)
library(stringr)
library(data.table)
#maindir = "~/University Of Houston/Price, Daniel M - Social Network Hypergraphs/"
maindir = "~/Downloads/UH_OneDrive/OneDrive\ -\ University\ Of\ Houston/Social\ Network\ Hypergraphs/" #Dan at home
#maindir = "~/Downloads/OneDrive\ -\ University\ Of\ Houston/Social\ Network\ Hypergraphs/" #Dan at work
housingdir = paste0(maindir,"HCAD/")
houstondatadir = paste0(maindir,"HoustonCityData/") 
censusdir = paste0(maindir,"Census/") 
vintage = "2019"
housingStockFromRDS = TRUE 
#numberOfCores = 1
state = 48 #48 Texas; 22 Louisiana
county = 201 #8 county region: 201 Harris; 157 Fort Bend; 167 Galveston; 039 Brazoria; 071 Chambers; 291 Liberty; 339 Montgomery; 473 Waller ; other place FIPS are longer
tract = "*"
Sam_seed = 135
#you don't need a censuskey if you're not pulling new files down; you can only use this one if you have correct access to the OneDrive
censuskey <- readLines(paste0(censusdir, "2017", "/key"))
```


For new file, and need a bit of a preamble

We're going to begin with the 2010 block group data table, P28 - Householdtype by Household Size by Race and Ethnicity. We start here not because it provides the greatest granularity, although it is by block group, but because it has the best structured relationality, around which commutative triangles can be built. The longer idea is to see the census bureau's copy of the full data representation as being both perfectly commutable in the ways it can be represented and granular at an individual level (again, setting aside difficulties with their collection and category choice). There are then ways in which the census bureau produces tables, with different concerns at different stages and with different products, but they both try to ensure the structure of commutability is maintained within the particular representation and to ensure that the people interpreting the data understand how it relates statistically as a subset - which is to say, how the granularity of the presentation is related to the underlying granularity as the chance that when you see someone from a particular subset, they fit into the demographics of the larger group. [that could be better phrased, but trying to get at difference between set theory and type theory with the categorical spin]

Let's download P28 (Household Type by Size by Race and Ethnicity) and look at it.

```{r download hhtype hhsize race eth bg}
dec_bgHH_type_size_re_data_from_census_10 <- 
  censusData_byGroupName(censusdir, vintage="2010", state, censuskey, 
                         groupname = "P28",county_num = "201",
                         block="block_group",api_type="dec/sf1",path_suff="est.csv")
```

Then do our basic checks:
```{r hh_type_size_re test problems}
dec_bgHH_data_10 <- as.data.table(dec_bgHH_type_size_re_data_from_census_10)
    percent_na <- dec_bgHH_data_10[,sum(is.na(.SD))] / 
      (dec_bgHH_data_10[,sum(!is.na(.SD))]+dec_bgHH_data_10[,sum(is.na(.SD))])
    paste("Percentage of NAs in file:",as.integer(100*percent_na))
#make the numbers into numeric type - some operations won't work with either integer or character, although we could play with optimizing it
    dec_bgHH_data_10[,4:ncol(dec_bgHH_data_10)] <- dec_bgHH_data_10[,lapply(.SD[,4:ncol(dec_bgHH_data_10)], as.numeric)]
#multiplying the side labeled only "Total" by 2:
test <- colSums(dec_bgHH_data_10[label=="Total",4:ncol(dec_bgHH_data_10)])*2 ==
      colSums(dec_bgHH_data_10[label!="Total",4:ncol(dec_bgHH_data_10)])
#see if any of the tests don't match; if false, need to go back and check on what happened
length(test[test==F])==0
hh_totals_bg <- dec_bgHH_data_10[label=="Total"&concept=="HOUSEHOLD TYPE BY HOUSEHOLD SIZE",4:ncol(dec_bgHH_data_10)]
paste0("Number of Households total for Harris County by block_group: ", sum(hh_totals_bg[,]))
```

Now we need to convert the census representation into a representation of individual households.

```{r expand P28 into dec_bgHH_10}
    race_codes <- c("A","B","C","D","E","F","G")
    dec_bgHHr_10 <- dec_bgHH_data_10 %>%
      pivot_longer(4:ncol(dec_bgHH_data_10),names_to = "geoid", values_to = "number_sams") %>% 
      mutate(
        race = substr(name,5,5),
        label = str_remove_all(label,"Total!!")) %>%
      filter(label != "Total") %>% #keep only the ones that aren't aggregated
      separate(label, c("family","hh_size"), sep = "!!", remove = F, convert = FALSE) %>%
      filter(!is.na(hh_size) & race%in%race_codes) %>% #to get rid of aggregations by family
      uncount(number_sams,.id = "hhr_size_id",.remove = TRUE) 
    dec_bgHHr_10 <- as.data.table(dec_bgHHr_10) #dyplyr had stripped it of dt
    paste0("Number of households in file: ", nrow(dec_bgHHr_10))
    #break into race and ethnicity files
    nrow(dec_bgHHr_10)==sum(hh_totals_bg[,])
    #and same for ethnicity
    dec_bgHHe_10 <- dec_bgHH_data_10 %>%
      pivot_longer(4:ncol(dec_bgHH_data_10),names_to = "geoid", values_to = "number_sams") %>% 
      mutate(
        ethnicity = substr(name,5,5),
        label = str_remove_all(label,"Total!!")) %>%
      filter(label != "Total") %>% #keep only the ones that aren't aggregated
      separate(label, c("family","hh_size"), sep = "!!", remove = F, convert = FALSE) %>%
      filter(!is.na(hh_size) & ethnicity%in%c("H","I")) %>% 
      uncount(number_sams,.id = "hhe_size_id",.remove = TRUE) 
    dec_bgHHe_10 <- as.data.table(dec_bgHHe_10) #dyplyr had stripped it of dt
    paste0("Number of households with ethnicity attributes in file: ", nrow(dec_bgHHe_10))
    #should clean up
    rm(dec_bgHH_data_10)
    rm(dec_bgHH_type_size_re_data_from_census_10)
```


Now let's get P17, average household size by age (with people under 18 in household or not) and race and ethnicity by block group. It adds the question of what happens with other sorts of representations besides summation or subset, with average being easy to understand and important to the underlying idea of maintaining structure. The additional information is a hint about how households with people under 18 differ from those without, by race and ethnicity. Since there is also a total, which we can generate separately from the dec_bgHHr_10 file we can check our process as well as give further shape to the representation for the two age groups.  

```{r download avg hhsize race eth bg}
dec_bgHH_avg_size_re_data_from_census_10 <- 
  censusData_byGroupName(censusdir, vintage="2010", state, censuskey, 
                         groupname = "P17",county_num = "201",
                         block="block_group",api_type="dec/sf1",path_suff="est.csv")
```
Then do our basic checks:
```{r hh_avg_size_re test problems}
dec_bgHH_avg_size_data_10 <- as.data.table(dec_bgHH_avg_size_re_data_from_census_10)
    percent_na <- dec_bgHH_avg_size_data_10[,sum(is.na(.SD))] / 
      (dec_bgHH_avg_size_data_10[,sum(!is.na(.SD))]+dec_bgHH_avg_size_data_10[,sum(is.na(.SD))])
    paste("Percentage of NAs in file:",as.integer(100*percent_na))
#make the numbers into numeric type - some operations won't work with either integer or character, although we could play with optimizing it
    dec_bgHH_avg_size_data_10[,4:ncol(dec_bgHH_avg_size_data_10)] <- dec_bgHH_avg_size_data_10[,lapply(.SD[,4:ncol(dec_bgHH_avg_size_data_10)], as.numeric)]
#multiplying the side labeled only "Total" by 2:
pop_avgs_bg <- dec_bgHH_avg_size_data_10[label=="Average household size!!Total"&concept=="AVERAGE HOUSEHOLD SIZE BY AGE",4:ncol(dec_bgHH_avg_size_data_10)]
paste0("Average family size for Harris County: ", round(mean(colMeans(pop_avgs_bg[,])),2)) # sum(pop_avgs_bg[,])/ncol(pop_avgs_bg) #to remember colMeans
#There is considerable variation at the block_group level
paste0("Minimum average household size for Harris County block groups: ",min(pop_avgs_bg[,]))
paste0("Maximum average household size for Harris County block groups: ",max(pop_avgs_bg[,])) 
paste0("Standard deviation for average household size for Harris County block groups: ",round(sd(pop_avgs_bg[,]),2))
```

We pull in P17 (Average Household Size) in order to ask how one retains the structure of the average without violating the other commutative structures. Our strategy will be to order each household in a subtype (block_group x race) as either above or below the average. For each subtype, we already know the distribution, and our first task will be to show that we can maintain the structure of the average in the new representation while still respecting the other distributions. Since they are distributed into a set number of places afterward, we don't need to approximate a normal distribution in advance. We'll do it first for the total average household size by race, which is a known amount and can be generated directly from the table in P17 and as a calculation on the data in P28. Then we'll generate the subtypes from the averages for households with members below 18 and those with only members above 18 years of age. In order to do that, we need to know the number of households in each category, which we'll be able to add from P19 (Household Size by Household Type by Presence of Own Children) and P20 (Households by Presence of People Under 18 Years by Household Type by Age of People Under 18 Years), although not by race. The challenge is whether a technique that depends on a deliberately constructed space can provide a meaningful distribution of individuals within that space, which respects the structures that were important in the representation of the problem.  Our purpose is to generalize beyond the current example by showing concretely the sense in which a structured space is a more effective way of representing the process of analysis through a guided abstraction; showing how multiple structures can be respected in the construction of a solution is an important step in that process.  

Now we'll reshape P17 (Average Household Size) to use more efficiently later the average number of households by both race and ethnicity, for households with and without people under 18 in them, for each block_group. 

```{r expand P17 into dec_bgHH_avg_size_data_10}
    dec_bgHH_avg_size_10 <- dec_bgHH_avg_size_data_10 %>%
      pivot_longer(4:ncol(dec_bgHH_avg_size_data_10),names_to = "geoid", 
                   values_to = "avg_hh_size") %>% 
      mutate(race = substr(name,5,5))   
    dec_bgHH_avg_size_10 <- as.data.table(dec_bgHH_avg_size_10) #dyplyr had stripped it of dt

    #should clean up
    
    rm(dec_bgHH_avg_size_re_data_from_census_10)
```

As a quick check, the averages directly reported as "Total" in P17 should match calculations on the actual description in P28. We will check those, first, as proof that we can make the simplest case work, and then construct the pieces that allow for a sub-typing to be represented in the distribution of the data. We'll test on total, "White Alone," and "White Alone, not Hispanic or Latino."

```{r compare P17 dec_bgHH_avg_size avg to P28 dec_bgHH avg}
  dec_bgHHr_10 <- as.data.table(dec_bgHHr_10)
  dec_bgHHr_10[,("hh_size_n"):=as.numeric(substr(hh_size,1,1))]
  dec_bgHHr_10[,("avg_hh_size_bg"):=round(mean(hh_size_n),2),by=.(geoid)]
  
  dec_bgHHr_10[,("avg_hh_size_bg_r"):=round(mean(hh_size_n),2),by=.(geoid,race)]
  
  dec_bgHHe_10[,("hh_size_n"):=as.numeric(substr(hh_size,1,1))]
  dec_bgHHe_10[,("avg_hh_size_bg_e"):=round(mean(hh_size_n),2),by=.(geoid,ethnicity)]
  
  paste0("All")
  summary(dec_bgHH_avg_size_10[name=="P017001",avg_hh_size])
  summary(dec_bgHHr_10[,(avg_hh_size_bg)])
  paste0("Black")
  summary(dec_bgHH_avg_size_10[name=="P017B001",avg_hh_size])
  summary(dec_bgHHr_10[race=="B",(avg_hh_size_bg_r)])
  paste0("Hispanic")
  summary(dec_bgHH_avg_size_10[name=="P017H001",avg_hh_size])
  summary(dec_bgHHe_10[ethnicity=="H",(avg_hh_size_bg_e)])
  
  #rm(dec_bgHH_avg_size_data_10)
```

We remark immediately on the maximum value for Black households being 10.5, when the highest reported value in P28 is 7. The block group in question (48_201_233703_2) turns out to only have two Black households listed in P28, both in the "7-or-more-person-household". There are 293 households total. We are assuming that it's not a reporting mistake, but just an unusual situation. Remember that the summary statistics are for all the averages across block groups and that only the average for that block group is reported in P17. For the total households in the block group that has the outliers (48_201_233703_2), the summary across all the households in P28 has a median a little higher than the mean, but nothing out of the ordinary and relatively close to the reported mean in P17. The fact that the actual values are whole numbers actually gives us a clue for how to think about the distribution we aim to do in the end.

```{r 48_201_233703_2 summary for households}
summary(dec_bgHHr_10[geoid=="48_201_233703_2",(hh_size_n)])
paste0("Reported average in P17: ",dec_bgHH_avg_size_10[name=="P017001"&geoid=="48_201_233702_3",avg_hh_size])
```

We will implement a matching process on the households in two steps. First, we create a number for every household that is either above or below the average for that race category, by geoid and race, using sample() to create a random distribution centered on the average. Then we will order the households in the category that is one higher in the embedding (in this case, all households, but could also be a larger geographic area) by that new number and assign the available sizes as a vector. This preserves the structure of the differing averages - even given that we do not know anything else about the distribution. We are testing it this time, since we have a ground truth for households by race. If it works, we will then use the same technique to create sub-types by households with and without persons under 18 by race.

```{r add match logic to household size test}
    #create number for each hh on both sides of the average by race
    dec_bgHHr_10[,("match_avg_r_num"):=avg_hh_size_bg_r+
          sample((-.N/2):.N/2,.N,replace=FALSE)/.N,by=.(geoid,race)]
    #get the available household sizes, ordered as ascending, for each block group
    dec_bgHHr_10[order(hh_size_n),("hh_sizes_available"):=as.vector(.SD[,hh_size_n]),by=.(geoid)]
    #order all races together by the new number
    dec_bgHHr_10[order(match_avg_r_num),("hh_size_generated"):=hh_sizes_available[.N],by=.(geoid)]
```

Let's look at some statistics.

plan:
get avg.age by race onto dec_bgHHr_10 from P17

Run the same way.

have to do it for each race, creating a match ID that doesn't have race in it, and is just assigning a seq.int based on .N on the sorted input.
matches puts in from ordered vector of sizes available for the group that includes all the races (works trivially for just that one). 
test will be tables by hh_size and hh_size by race/eth

if that works, 
do the same for under 18 and over 18 households - but for that, we need to know how many fit in each...
Using P19, P20, and P21, we should be able to shape P18 - moving each avg into dec_copy, too. - should be close on conserving avg. and distribution in categories
and check that against P28 or not.

Use H16 for Tenure by HH_size by race and ethnicity; [[should look at avg hh size by tenure, too- H16, along with other rent_own info]]

Now let's get P18, household type by race and ethnicity, which has more detail in the type of household.
```{r download hhtype hhsize race eth bg}
dec_bgHH_type_re_data_from_census_10 <- 
  censusData_byGroupName(censusdir, vintage="2010", state, censuskey, 
                         groupname = "P18",county_num = "201",
                         block="block_group",api_type="dec/sf1",path_suff="est.csv")
```

Then do our basic checks:
```{r hh_type_re test problems}
dec_bgHH_type_data_10 <- as.data.table(dec_bgHH_type_re_data_from_census_10)
    percent_na <- dec_bgHH_type_data_10[,sum(is.na(.SD))] / 
      (dec_bgHH_type_data_10[,sum(!is.na(.SD))]+dec_bgHH_type_data_10[,sum(is.na(.SD))])
    paste("Percentage of NAs in file:",as.integer(100*percent_na))
#make the numbers into numeric type - some operations won't work with either integer or character, although we could play with optimizing it
    dec_bgHH_type_data_10[,4:ncol(dec_bgHH_type_data_10)] <- dec_bgHH_type_data_10[,lapply(.SD[,4:ncol(dec_bgHH_type_data_10)], as.numeric)]
pop_totals_bg <- dec_bgHH_type_data_10[label=="Total"&concept=="HOUSEHOLD TYPE",4:ncol(dec_bgHH_type_data_10)]
paste0("Number of Households total for Harris County by block_group: ", sum(pop_totals_bg[,]))
sum(pop_totals_bg[,])==nrow(dec_bgHHr_10)
```

Then expand into the representation of individual households by both ethnicity and race.
```{r expand P18 into dec_bgHH_type_10}
#break into race and ethnicity files
    race_codes <- c("A","B","C","D","E","F","G")
    dec_bgHHr_type_10 <- dec_bgHH_type_data_10 %>%
      pivot_longer(4:ncol(dec_bgHH_type_data_10),names_to = "geoid", values_to = "number_sams") %>% 
      mutate(
        race = substr(name,5,5),
        label = str_remove_all(label,"Total!!"),
        label = str_remove_all(label,"!!Other family")) %>%
      filter(label != "Total") %>% #keep only the ones that aren't aggregated
      separate(label, c("family","family_details"), sep = "!!", remove = F, convert = FALSE) %>%
      filter(!is.na(family_details) & race%in%race_codes) %>% #to get rid of aggregations by family
      uncount(number_sams,.id = "hhr_type_id",.remove = TRUE) 
    dec_bgHHr_type_10 <- as.data.table(dec_bgHHr_type_10) #dyplyr had stripped it of dt
    paste0("Number of households in file: ", nrow(dec_bgHHr_type_10))
    nrow(dec_bgHHr_10)==nrow(dec_bgHHr_type_10)
    
    #multiplying the side labeled only "Total" by 2:
    dec_bgHHr_type_10[,4:ncol(dec_bgHHr_type_10)] <- dec_bgHHr_type_10[,lapply(.SD[,4:ncol(dec_bgHHr_type_10)], as.numeric)]
    #and same for ethnicity
    dec_bgHHe_type_10 <- dec_bgHH_type_data_10 %>%
      mutate(
        ethnicity = substr(name,5,5),
        label = str_remove_all(label,"Total!!"),
        label = str_remove_all(label,"!!Other family")) %>%
      filter(label != "Total") %>% #keep only the ones that aren't aggregated
      pivot_longer(4:ncol(dec_bgHH_type_data_10),names_to = "geoid", values_to = "number_sams") %>% 
      separate(label, c("family","family_details"), sep = "!!", remove = F, convert = FALSE) %>%
      filter(!is.na(family_details) & ethnicity%in%c("H","I")) %>% 
      uncount(number_sams,.id = "hhe_type_id",.remove = TRUE) 
    dec_bgHHe_type_10 <- as.data.table(dec_bgHHe_type_10) #dyplyr had stripped it of dt
    paste0("Number of households with ethnicity attributes in file: ", nrow(dec_bgHHe_10))
    nrow(dec_bgHHe_10)==nrow(dec_bgHHe_type_10)
    #should clean up
    rm(dec_bgHH_type_data_10)
    rm(dec_bgHH_type_re_data_from_census_10)
```

Then do P22, HOUSEHOLD TYPE BY AGE OF HOUSEHOLDER, but which doesn't have race/eth
(how does that relate to P17? look at totals)

```{r basic household data download}
#block - sf1 - P15 and P16 (eth and race of hh) P18 (hhtype by race/eth) P22 (hhtype by age of hh) p28 (hhtype by hhsize by race/eth)
#plan - looks like P17 and P18 have much more detail than P28, so combine P17 with P28, then P18 with P28xP17
#then combine P16 with P28xP17xP18 and P15 with P28xP17xP18xP16   

#tract - sf2 - (Tenure by hhtype by age of hh - HCT9) - more age_groups and has tenure
```

```{r hh_relation download block}

dec_hh_relation_data_from_census_10 <- censusData_byGroupName(censusdir, vintage="2010", state, censuskey, 
                                                                groupname = "P29",county_num = "201",
                                                                block="block_group",api_type="dec/sf1",path_suff="est.csv")
```



The redistricting data collected in 2010 reports population estimates in yet a different format. It has one table that has races and ethnicity data for everyone over 18 and one that has it for everyone, with no ages attached. The race data gives more details on the composition of "Two or More Races" but nothing else new. The ethnicity file gives block level data for Hispanic or Latino who don't identify as White. Gives slightly more contour, but not much, and risks big differences on age and ethnicity or race per block group. (Although some contour is better than none!)

```{r pl data downloaded}
    dec_eth_block_data_from_census_10 <- censusData_byGroupName(censusdir, vintage="2010", state, censuskey, 
                                                                      groupname = "P2",county_num = "201",
                                                                      block="block_group",api_type="dec/pl",path_suff="est.csv")
    dec_race_block_data_from_census_10 <- censusData_byGroupName(censusdir, vintage="2010", state, censuskey, 
                                                                groupname = "P1",county_num = "201",
                                                                block="block_group",api_type="dec/pl",path_suff="est.csv")
    dec_eth_over18_block_data_from_census_10 <- censusData_byGroupName(censusdir, vintage="2010", state, censuskey, 
                                                                      groupname = "P4",county_num = "201",
                                                                      block="block_group",api_type="dec/pl",path_suff="est.csv")
    dec_race_over18_block_data_from_census_10 <- censusData_byGroupName(censusdir, vintage="2010", state, censuskey, 
                                                                groupname = "P3",county_num = "201",
                                                                block="block_group",api_type="dec/pl",path_suff="est.csv")
 
    
```




Then have the tract level details join into the bg representation? Should discuss whether to start with the household stuff - check if it has the PCT level of detail on ethnicity anywhere... 
If not, can just save the demographic_bg to the OneDrive and start from there.




https://www2.census.gov/programs-surveys/decennial/2010/technical-documentation/complete-tech-docs/summary-file/sf1.pdf
put in households
add P15 or P16, then other hh stuff that can be added without problems, then add people in
also look at H9
P21 should also be good; p29, p30...

have to think about how family info is different from hh

group quarters are needed b/c hh don't include them
```{r group quarters to add}
dec_group_quarters_block_data_from_census_10 <- 
  censusData_byGroupName(censusdir, vintage="2010", state, censuskey, 
                         groupname = "P5",county_num = "201",
                         block="block_group",api_type="dec/pl",path_suff="est.csv")
```



expand from census

rearrange so that they all add to same whole and then figure out how to distribute them among that space

tests of each step

discussion of power sets vs. categories? 

redoing HCAD first to help with generation of 2011 - a space to move into...


