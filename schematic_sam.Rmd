---
title: "Schematic Sam"
author: "Dan Price"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
geometry: margin=1in
fontsize: 11pt
documentclass: article
header-includes: 
  - \usepackage{tikz}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
 
```{r prelims, include=FALSE}
source('BaseScripts/Census_Data.R') #move out of BaseScripts?
source('tests.R') #need to redo! Using for some of bgSAR now, but not consistent
#library(dplyr)
library(tidyr)
library(data.table)
library(stringr)
maindir = "~/University\ Of\ Houston/Engaged\ Data\ Science\ -\ Data/" #Dan Studio
#maindir = "~/Downloads/UH_OneDrive/OneDrive\ -\ University\ Of\ Houston/Social\ Network\ Hypergraphs/" #Dan at home
#maindir = "/Users/areb219/Library/CloudStorage/OneDrive-UniversityOfHouston/Social\ Network\ Hypergraphs/" #Dan on AREB219 laptop
#maindir = "~/OneDrive\ -\ University\ Of\ Houston/Social\ Network\ Hypergraphs/" #Dan at work
housingdir = paste0(maindir,"HCAD/")
houstondatadir = paste0(maindir,"HoustonCityData/") 
censusdir = paste0(maindir,"Census/") 
vintage = "2020"
state = "48" #48 Texas; 22 Louisiana
county = "*" #8 county region: 201 Harris; 157 Fort Bend; 167 Galveston; 039 Brazoria; 071 Chambers; 291 Liberty; 339 Montgomery; 473 Waller ; other place FIPS are longer
#st_county = paste0(state,county) #"48201"
tract = "*"
Sam_seed = 135
#you don't need a censuskey if you're not pulling new files down; you can only use this one if you have correct access to the OneDrive
censuskey <- readLines(paste0(censusdir, "2017", "/key"))
```

Naming conventions: 
bg_ = block_group; tr_ = tract; zip_ = zcta; city_ = city; county_ = county; 
pop = individual level;
hh = household;
gq = group quarters;
_data_from_census for the raw census data
_dec = decennial; _acs = American Community Survey; years are included when known to only work for those years...
SARE = Sex, Age, Race, Ethnicity; race_ and eth_ when too confusing
_DT for a data.table (need to think about how to remove not needed files)

2020 count problems
https://www.census.gov/newsroom/blogs/random-samplings/2023/12/recommendations-2020-pes-coverage-results-in-vintage-2023-pop-estimates.html
https://api.census.gov/data/2020/dec/pes.html
There are numbers we can use to nudge toward the post-enumeration survey from 2020, but not for 2010 or 2000.
Importantly, from above, for 2020:
The Hispanic or Latino population had a 4.99% undercount.
The Black or African American population had a 3.30% undercount.
The American Indian or Alaska Native population living on reservations had a 5.64% undercount.
The White alone, non-Hispanic population had a 1.64% overcount.
The Asian population had a 2.62% overcount.

Some folks have tried to use self-response rate as an indicator - https://www.census.gov/data/developers/data-sets/decennial-response-rates.html

2010 count problems (also didn't correct for estimations)
https://www.census.gov/programs-surveys/decennial-census/about/coverage-measurement/pes.2010.html
https://www.census.gov/data/developers/data-sets/decennial-response-rates.2010.html#list-tab-45070917
https://www.census.gov/programs-surveys/decennial-census/about/coverage-measurement/pes/2010/ccm-results-texas.html


2000 count problems
vgl: 2000 revision: https://www2.census.gov/programs-surveys/decennial/2000/program-management/5-review/ace/pp-60r.pdf
https://www2.census.gov/programs-surveys/decennial/2000/program-management/5-review/ace/pp-45r.pdf
https://www.census.gov/library/working-papers/2011/demo/POP-twps0091.html and:
https://www2.census.gov/programs-surveys/decennial/2000/program-management/5-review/ace/pp-41r.pdf
"The DA estimates for race-sex groups in 2000 reveal the persistence of the differential
undercount of one group as measured by DA--Black males–though the differential is reduced
from 1990 and earlier censuses. For Black males, the group with the highest net undercount rates
historically, the rate of 5.15 percent for 2000 is 3.0 percentage points below the 1990 estimate of
8.13 percent (Table 2). For Black females, the rate of 0.52 percent is appreciably lower than the
1990 estimate of 3.05 percent (a drop of 2.5 percentage points). The DA estimates for NonBlack
males shows a small net undercount of 0.21 percent, while a net census overcount of 0.78 percent
is estimated for NonBlack females. Like Black net undercount rates, the NonBlack rates are
appreciably reduced from 1990. The reduction was proportionately greater for Black, however,
lowering the Black-NonBlack differential undercount from 4.44 to 3.07 percentage points."



At some point: https://www2.census.gov/programs-surveys/decennial/2020/data/apportionment/2020CensusOverseasCounts.xlsx
and: a discussion of https://www.census.gov/programs-surveys/decennial-census/decade/2020/planning-management/count/service-based-enumeration.html
some of the homeless are in group quarters, but the service-based enumeration is supposed to be higher. Looks like gq 702, 704 and 706
https://www.census.gov/programs-surveys/decennial-census/decade/2020/about/residence-rule.html

data table guides provided by census: (also downloaded under censusdir/2020) https://www2.census.gov/programs-surveys/decennial/2020/program-management/data-table-guide-dhc-dp.xlsx
and: https://www2.census.gov/programs-surveys/decennial/2020/technical-documentation/complete-tech-docs/demographic-and-housing-characteristics-file-and-demographic-profile/2020census-demographic-and-housing-characteristics-file-and-demographic-profile-techdoc.pdf
[note noninstitutional group quarters and new defs for college housing]

https://www2.census.gov/programs-surveys/decennial/2020/technical-documentation/complete-tech-docs/demographic-and-housing-characteristics-file-and-demographic-profile/2020census-demographic-and-housing-characteristics-file-and-demographic-profile-techdoc.pdf
is extensive and includes 4-2 discussion of invariants and privacy-loss budget relative to differential privacy noise. We are not trying to pierce the veil of differential privacy, but to make the sense of deliberately constructed data questions come to the fore.
"The total population for each state is held invariant—
used exactly as enumerated and with no noise added. Similarly, the total number of housing units
in each census block and the number and major type of each occupied group quarters facility in
each census block are also held invariant."
#Plan 
Cut out the discussion

Do population for 2020, with notes to where to find the already worked out stuff for 2010
Do sare, bgSARE with specifications from P1 and PCT
Do household

Do post-enumeration fix
Point is that after you've expanded to all the products, you are distributing among them.
You multiply the percentages by each category given, then the others provide a limit for the distribution from the other intersecting side. With just the variables given in PES, what can we do...

https://www.census.gov/data/developers/data-sets/decennial-response-rates/2020.html goes to tract level on self-response rates; could use it vs. race to see which is better for getting at total...

Idea is that sampling from a concept space is always happening - you're not sampling individuals from a total constructed by nature, but from one of many ways that you might do so. Some of them will make more sense than others, of course.

Might compare it with what you get from doing cross-tabs with the 100k folks in a PUMS, because that gives a sense of what it means for something to be sampled from a constructed space...

Think about stuff for stats in general and comparison with ACS on margin of error
https://www2.census.gov/programs-surveys/acs/tech_docs/statistical_testing/2018_Instructions_for_Stat_Testing_ACS.pdf?
https://ccrpc.org/wp-content/uploads/2015/02/american-community-survey-guide.pdf
https://www.census.gov/content/dam/Census/library/publications/2018/acs/acs_general_handbook_2018_ch07.pdf for discussion of error reporting
https://www.census.gov/programs-surveys/acs/technical-documentation/variance-tables.html to calculate new margins for combined geographies




Need to decide how to deal with blocks that are in HCAD but not in county=="201" - border cases? take part of population? exclude?


As we saw in the previous section on problems with the American Community Survey, there are practical reasons we need to move back to the 2010 and 2020 decennial census reports, especially the detailed geographic reports. There are two main technical documents for the tables created for smallest area (block group) demographic data in each decade. 

The two have similar tables, but different levels of detail provided. They provide some information on how to download the files, although we're using the R library censusapi in our script, CensusData.R, to make calls.
If you want to look at the details, go to the List of Tables (Matrices) to see what sorts of reports are produced. The first is populations summarized (with a few exceptions) at the block level: [2010 block level summary](https://www2.census.gov/programs-surveys/decennial/2010/technical-documentation/complete-tech-docs/summary-file/sf1.pdf) [2020 technical summary block and tract](https://www2.census.gov/programs-surveys/decennial/2020/technical-documentation/complete-tech-docs/demographic-and-housing-characteristics-file-and-demographic-profile/2020census-demographic-and-housing-characteristics-file-and-demographic-profile-techdoc.pdf)

and the second is for the tract level summaries: [2010 tract level summary](http://www2.census.gov/programs-surveys/decennial/2010/technical-documentation/complete-tech-docs/summary-file/sf2.pdf)
The table names that begin with PCT never go below the tract level, but occasionally have more detail in some of the concepts. The Census Bureau is bound by law to produce a count for the decennial census and it pairs that with only the basic demographic, household, and family data. Things like income, employment, and education (among many others) are modeled by the Census Bureau only for the American Community Survey, which tries to prevent the reconstruction of individual identities and location of individuals in particular tracts. They did this because early on there was a general recognition that such information would be used to violate people's expectations of privacy - they would be subject to advertising or perhaps harassment or prejudice - based on their honest answers to the census. Unfortunately, the financial interest in producing such information is quite large and most of that expected privacy has already been lost. We have no interest in breaking down even the walls that the census puts up. We are not calling out the Census Bureau for some sort of mistake. We are saying that in one of the most foundational products that people use for representing U.S. society, there is a way to think about how the structure pervades the construction of tables and other representations. Understanding that structure helps us point to some hidden opportunities in using population-level data, but also to limitations to thinking about a population of individuals with relations at a given time (the fundamental metaphor of the census, after all) instead of thinking about people on lived trajectories in relation with others being constrained or guided by structures. That one, for example, should address a problem by removing unnecessary barriers instead of adding capacity to the individual facing the barrier, is a (perhaps) surprising result of the method. 

Let's begin with PCT12, which is tract level data but has every age by year, gender, ethnicity and race. It has 101 possible age groups, with 1-99 years and then one for "100 to 104 years" and one for "105 to 109 years". It then has categories for all the built in race and ethnicity categories, with each person counted in the total, and every person categorized by race (there are tables for how many people had to have a race assigned by the census bureau, since they refused to provide one, but they tell us how many people have an assigned race and describe their protocols); Hispanic is a problematic category for counting, as well as for historical reasons, and is dealt with differently in the decennial and ACS reporting. Let's download table PCT12, do some quick checks, and then look at it.  

```{r look at PCT12}
#this gives you by every year at the tract level - could be a good example for adding together - PCTs never go below tract level


trSAR_dec_data_from_census <- 
  censusData_byGroupName(censusdir, vintage, state, censuskey, 
                         groupname = "PCT12",county_num = county,
                         block="tract",api_type="dec/dhc",path_suff="est") #dec/sf1 for 2010!!

#This is all of Texas - county number doesn't seem to matter. 
#trSAR_dec_data_from_census <- trSAR_dec_data_from_census %>%
#      select(name,label,concept,starts_with(st_county))
#needs to be numeric for the sum in the test
trSAR_dec_data_from_census_DT <- as.data.table(trSAR_dec_data_from_census)
begin <- Sys.time()
system.time(
trSAR_dec_data_from_census_DT[,4:ncol(trSAR_dec_data_from_census_DT)] <- 
  trSAR_dec_data_from_census_DT[,lapply(.SD[,4:ncol(trSAR_dec_data_from_census_DT)], as.numeric)]
)
end <- Sys.time()
paste0("Process took ",end-begin," to finish")
head(trSAR_dec_data_from_census_DT[,1:5])
```

A quick glance shows that this has reporting for every year of age and at fifteen different levels for race and ethnicity, which is considerably more specificity than the reporting under ACS or at the block group level, reported as the number of people who fall into that category for every census tract in the state. That specificity provides a very granular embedding context (or structured space) on the conceptual level but is less specific geographically. It has every tract for the entire state, but some of the larger tracts are divided into 6 block_groups, which provides considerably more geographic context. One of the goals of our current approach is to show why thinking about the reporting on basic concepts like sex and age should be thought of as a similar problem as geographic boundaries - i.e., that both should be thought of as an articulation of structure within the context where the individual is placed in the representation. By paying close attention to that problem of articulating a coherent and meaningful structure, we can make explicit which mathematical operations are justified when transforming between the various possible representations of the data. 

Just to give a sense for how testing for coherent structure arises from and resonates with the broader process of building the data representation, we include some of the very basic ways that we can test for consistency. The following are repeated for each download from the census, as we look for obvious problems with the file either as reported or as a result of an improper download (like asking for the wrong file). In this version, we have put a data.table wrapper around the census data and sum the number of NAs in the columns. Because of how the Census Bureau allows access to its APIs, public users without permission for certain levels of granularity will sometimes return a file with NAs but not consider that a problem and not produce an error. In this case, we decided to represent the number of NAs as a percentage, and not just an absolute count, because sometimes we want to use data that is reported for only some of the rows, even if NAs are reported in some of the other rows. We don't want the download to fail unless there are only NAs, but if there are any at all, we want to know about it and know where to look for the problem. In later downloads, several of these tests are gathered in a single function call in tests.R as census_table_check. One of our ongoing tasks is to better automate those tests.

```{r test for na}
    percent_na <- trSAR_dec_data_from_census_DT[,sum(is.na(.SD))] / 
      (trSAR_dec_data_from_census_DT[,sum(!is.na(.SD))]+trSAR_dec_data_from_census_DT[,sum(is.na(.SD))])
    paste("Percentage of NAs in file:",as.integer(100*percent_na))
    rm(percent_na)
```

After seeing that there are no NAs, we need to check to make sure that the reported totals at least add up - every so often the census makes mistakes that we need to clean up in some way, including very occasionally putting the wrong values in aggregation cells. As we look at the "label" column, there's a row that contains the total for each concept and for the whole. The rows that say only "Total" are given for every version of "concept" that is given. This means that the representations can be embedded in several different ways, while still counting as "total," and we need to account for that in our representation. In the rows that say more than just "total," there are also rows for total female and male, which means that adding all that side up automatically is twice as large as the rows that say "label" only. We had the whole state, so for our case we'll select down to county first. In the GEOID that contains the tract numbers, Texas is 48 and Harris county is 201. https://www.census.gov/programs-surveys/geography/guidance/geo-identifiers.html

```{r check for consistency on totals}
#there's a total for each concept and for the whole, but in the ones without a total, there are also total female and male.
#test_2010 <- colSums(trSAR_dec_data_from_census_DT[label=="Total",4:ncol(trSAR_dec_data_from_census_DT)])*2 ==
#      colSums(trSAR_dec_data_from_census_DT[label!="Total",4:ncol(trSAR_dec_data_from_census_DT)])
test <- colSums(trSAR_dec_data_from_census_DT[label=="!!Total:",4:ncol(trSAR_dec_data_from_census_DT)])*2 ==
      colSums(trSAR_dec_data_from_census_DT[label!="!!Total:",4:ncol(trSAR_dec_data_from_census_DT)])
#see if any of the tests don't match; if false, need to go back and check on what happened
length(test[test==F])==0
```

```{r using tests.R for trSAR}
result <- census_table_check(trSAR_dec_data_from_census_DT,"SEX BY SINGLE-YEAR AGE", "individuals", "!!Total:")
cat(result)
```

If we want to know only the row that gives us the official census total population per census tract, we can add in the designation for concept. We know more having looked at the calculations involving all rows, as above, because if any of the totals had not been equal, we could look for a data problem in the specific place in the tables where the error emerged. Let's get the official totals in a separate file, just so we can use it to check later. (We'll find that we need it right away). 

```{r get totals by tract}
pop_totals_tract <- trSAR_dec_data_from_census_DT[label=="!!Total:"&concept=="SEX BY SINGLE-YEAR AGE",4:ncol(trSAR_dec_data_from_census_DT)] #SEX BY AGE in 2010
paste0("Population total by tract: ", sum(pop_totals_tract[,]))
```

The same convenience set lets us know some other facts about the variation in size of the tracts in Texas. Shortly, we'll find better shortcuts for displaying summary statistics, but for now we just create a few quick measures.

```{r Harris tract stats}
paste0("Number of tracts: ", ncol(trSAR_dec_data_from_census_DT[,4:ncol(trSAR_dec_data_from_census_DT)]))
paste0("Average population size tracts: ", as.integer(mean(as.numeric(pop_totals_tract[,]))))
paste0("Median population size tracts: ", as.integer(median(as.numeric(pop_totals_tract[,]))))
paste0("Maximum population size tract: ", max(as.numeric(pop_totals_tract[,])))
paste0("Minimum population size tract: ", min(as.numeric(pop_totals_tract[,])))
#rm(trSAR_dec_data_from_census_DT)
```

Now that we have the information at the tract level, let's also pick up the block level data.

```{r block_group sex by age}
begin <- Sys.time()
bgSAR_dec_data_from_census <- 
  census_block_get(censusdir, vintage, state, censuskey,
  #censusData_byGroupName(censusdir, vintage, state, censuskey, 
                         groupname = "P12",county_num = county, 
                         block="block_group",api_type="dec/dhc",path_suff="est")
#bgSAR_dec_data_from_census_DT <- as.data.table(bgSAR_dec_data_from_census)
#bgSAR_dec_data_from_census_DT[,4:ncol(bgSAR_dec_data_from_census_DT)] <- 
#  bgSAR_dec_data_from_census_DT[,lapply(.SD[,4:ncol(bgSAR_dec_data_from_census_DT)], as.numeric)]
end <- Sys.time()
paste0("Process took ",end-begin," to finish")
```

For 2010: It would be nice to use this immediately as our base, but we quickly see it doesn't have as many rows breaking out race and ethnicity. It has nine total categories for race and ethnicity - losing most of the categories in ethnicity - and age is reported in odd aggregations that will make comparison difficult with other data reporting. Let's run a few quick tests on the download.
In 2020, they added more, so we have to change some.

```{r demography test problems}
#2010 check_summary <- census_table_check(bgSAR_dec_data_from_census_DT, "SEX BY AGE","individuals") #should get a function that fails appropriately
check_summary <- census_table_check(bgSAR_dec_data_from_census_DT, "SEX BY AGE FOR SELECTED AGE CATEGORIES","individuals","!!Total:")
cat(check_summary)
pop_totals_bg <- bgSAR_dec_data_from_census_DT[name=="P12_001N",4:ncol(bgSAR_dec_data_from_census_DT)]
sum(pop_totals_tract[,],na.rm = TRUE)==sum(pop_totals_bg[,],na.rm = TRUE)
paste0("Number of block groups: ", ncol(bgSAR_dec_data_from_census_DT[,4:ncol(bgSAR_dec_data_from_census_DT)]))
paste0("Average population size block groups: ", as.integer(mean(as.numeric(pop_totals_bg[,]),na.rm = TRUE)))
paste0("Median population size block groups: ", as.integer(median(as.numeric(pop_totals_bg[,]),na.rm = TRUE)))
paste0("Maximum population size block group: ", max(as.numeric(pop_totals_bg[,]),na.rm = TRUE))
paste0("Minimum population size block group: ", min(as.numeric(pop_totals_bg[,]),na.rm = TRUE))
rm(pop_totals_bg)
rm(pop_totals_tract)
rm(bgSAR_dec_data_from_census_DT)
rm(trSAR_dec_data_from_census_DT)
```

We note, very quickly, that the median tract is almost three times as large as the median block group, but there is a good deal of variability in size on both. 

Remember that we were trying to figure out how best to represent a city's population for largely heuristic purposes - we felt that being able to see how individuals were aggregated and represented would tell us something about how we could avoid some common pitfalls, both conceptually and numerically. If we were looking for just the most granular geographic account, we could just use the block level data, which would entail losing the distinctions for Hispanics who did not consider themselves part of the "White" race. The history of how race and ethnicity is applied in the census, and in Houston in particular, is very much part of the lesson, however, and we did not want to lose that. (Cf. detailed discussion in talking_about.RMD). 

We noticed, however, that if we stopped looking at the problem as whether or not the Census Bureau had accurately described a particular individual and started looking at the rules they were using for constructing a cohesive whole (i.e., a representation that would be suitable for multiple related tables to be created without creating contradictions). Instead of concentrating on what information we had that could tell us whether any particular individual should have a predicate assigned, we asked how many of each type is instantiated in each geographic group and what does that allow us to calculate about the values not directly provided by the given tables. The first example is easy, but it's still worth drawing out slowly to ensure we're on the same page.

NEED TO REDO
Let's look at a figure first: [Tract and block group merge](https://q.uiver.app/?q=WzAsMTAsWzEsMCwiUENUMTJcXFxcdHJTQVJFIl0sWzAsMiwidHJTQVJcXFxccmFjZVxcXzdcXDt4XFxcXHNleFxcO3hcXDthZ2VcXF8xMTAiXSxbMiwyLCJ0clNBRVxcXFxldGhuaWNpdHlcXF84XFw7eFxcXFxzZXhcXDt4XFw7YWdlXFxfMTEwIl0sWzEsMSwidG90YWxzXFxcXHNhbWVcXDtieVxcXFx0cmFjdFxcO2FuZFxcXFxjb21wbGV0ZVxcO2J5XFxcXGJvdGhcXDtyYWNlXFw7YW5kXFxcXGV0aG5pY2l0eSJdLFsxLDIsIlxcYnVsbGV0Il0sWzEsNywiUDEyXFxcXGJnU0FSRSJdLFswLDUsImJnU0FSXFxcXHJhY2VcXF83XFw7eFxcXFxzZXhcXDt4XFw7YWdlXFxfMjMiXSxbMiw1LCJiZ1NBRVxcXFxldGhuaWNpdHlcXF8yXFw7eFxcXFxzZXhcXDt4XFw7YWdlXFxfMjMiXSxbMiw0XSxbMiwzLCJcXGJ1bGxldCJdLFswLDEsInN1YnNldHMiLDEseyJjb2xvdXIiOlsxMjAsNjAsNjBdfSxbMTIwLDYwLDYwLDFdXSxbMCwyLCJzdWJzZXRzIiwxLHsiY29sb3VyIjpbMTIwLDYwLDYwXX0sWzEyMCw2MCw2MCwxXV0sWzEsMl0sWzIsMSwiY29tbXV0ZXMiXSxbMyw0LCJ0YWJsZXMgPSIsMSx7ImNvbG91ciI6WzMwMCw2MCw2MF19LFszMDAsNjAsNjAsMV1dLFs1LDYsInN1YnNldHMiLDAseyJjb2xvdXIiOlsxMjAsNjAsNjBdfSxbMTIwLDYwLDYwLDFdXSxbNSw3LCJzdWJzZXRzIiwyLHsiY29sb3VyIjpbMTIwLDYwLDYwXX0sWzEyMCw2MCw2MCwxXV0sWzYsN10sWzcsNiwiZG9lc1xcO25vdFxcXFxjb21tdXRlIiwwLHsiY29sb3VyIjpbMCw2MCw2MF19LFswLDYwLDYwLDFdXSxbMiw3LCJqb2luXFw7YnlcXFxcc2V4XFw7eFxcO2FnZVxcXzIzXFw7eFxcXFxyYWNlIiwxLHsiY29sb3VyIjpbMjcwLDYwLDYwXX0sWzI3MCw2MCw2MCwxXV0sWzgsNiwiY29tbXV0ZXNcXFxcc29tZVxcO2xvc3NcXFxcYXNzaWduZWQiLDFdLFsxLDldXQ==). [Image of same](trSARE_bgSARE.png)

PCT12 is the name of the table from the Census Bureau that we just downloaded at the tract level. For shorthand version in the R code, we name it trSARE (i.e., __tr__act, __s__ex, __a__ge, __r__ace, __e__thnicity). The subtables are trSAR and trSAE, with the number of factors given for each of the categories in the table (so that race_7 means there are 7 race categories). Inside the code, we may append the year or the geography, as appropriate. For that tract level table, we have ages by year, and we know how many in each tract are "Hispanic or Latino" by all the possible race categories, and not just "White/ Not White." 
From the bottom, you have the much better geographic granularity of block groups and not tracts, but you only have two categories by ethnicity and only 23 categories for age. We will do a straightforward join and assign the ones that we can, but we find that some of the other tables available with the decennial census can help us make sure we aren't mismatching some of the information. 

For our case, this is a heuristic for asking explicitly about the structure of representation in the census and what emerges as a result of that structure. In the somewhat simplified case before us, we are trying to completely join ethnicity with race at the block level. The paired question, which we are trying to open up and make explicit, is how that structure could be differently constructed by future researchers and what it would mean to use an internal analysis of these structures for original insight into neighborhood dynamics.


#Embedding Calculations in Structured Spaces. 

In our current project, we are trying to identify and leverage the structures in place in the data tables trSARE and bgSARE. For the next step, we need to transform the counts we have for demography so that each person is represented as having properties, including geography and demography. From a purely technical side, this is just transposing the columns and the rows, so that each row is a census tract, and the columns correspond to the attributes that had been in the columns. Then, we will expand the number of individuals with those characteristics by just adding a row for each individual represented in the count. One can think about this equivalently as having created individuals with predicates, following the logic of the tables, or - as we propose as an alternative - we can take the predicates as structures of a shared space, where individuals expand into that structure according to rules that govern the individuals' potential pathways. Those "rules" are given either directly or indirectly from other tables, with other predicates, but in some way still referring to the same individuals within the same census tract. How to combine those predicates is the task that ran us aground the first time; how to construct a space of possible predication in terms of the individuals inhabiting that space is the question we are now pursuing. Heuristically, we are repeating a bit of the trauma of having run into a couple of walls trying to naively reconstruct individuals with predicates from these tables. We assume that many others would have had the same first naive reaction, and that it's worth stepping through the various parts at least once.

Let's take a closer look at the tract-level data, as the most specific for year and race category, and then add the block_group information because that gives us important geographic differences. We'll work with only Harris County at this point, since we assume that the structure is repeated, by explicit design of the Census Bureau, across the entire population.

First, we need to identify the rows which, if added together, give us a complete and non-repeating set of the population. There is one way to do that with the overall total row, with the two gender total rows, and with all of the individual age rows without the totals. Unfortunately, the census reports have a somewhat idiosyncratic way of reporting the data, and the way to identify these rows is not always simple. This case is relatively easy, and a good example to start with. The "label" column has three components, separated by double exclamation points. (They made changes in the way the separations work in 2019, so these small scripts will have to be modified for later years. The decennial and ACS also have small differences that have to be accounted for, as we will see. A lot of the difficult work is the tedious effort involved in cleaning up the data for processing, but cleaning and structuring are similar tasks, and they provide a good example of what it means to be clear about the structure that sustains the potential analyses).

We can use a little trick because of how the R library dyplyr performs the translation and expansion of the representation, so that we're looking at rows of people with geographic and demographic properties and not rows of categories against columns of geography. We will get a warning that NAs were introduced by coercion, but it happens that those will be the rows that we want to exclude in any case. We'll show the warnings, here, but suppress them later.

```{r expand trSARE for the tracts in PC12, warning = FALSE}
#not using DT for this
system.time(
trSARE_dec <- trSAR_dec_data_from_census %>%
  pivot_longer(4:ncol(trSAR_dec_data_from_census),names_to = "tract", values_to = "number_sams",
               names_transform = list(tract=as.character)) %>%
  separate(label, c("total","sex","age"), sep = ":!!", remove = F, convert = FALSE) %>%
  mutate(re_code = substr(name,6,6),
         race = str_replace(concept,"SEX BY SINGLE-YEAR AGE \\(",""),
         race = str_replace(race,"\\)",""),
         age = str_replace(age, "Under 1 year", "0"),
         age = str_replace(age,"year"," year"),
         age = as.integer(substr(age,1,3))
         ) %>%
  filter(number_sams > 0, !is.na(age))
#2010trSARE_dec <- trSAR_dec_data_from_census %>%
#  pivot_longer(4:ncol(trSAR_dec_data_from_census),names_to = "tract", values_to = "number_sams",
#               names_transform = list(tract=as.character)) %>%
#  separate(label, c("total","sex","age"), sep = "!!", remove = F, convert = FALSE) %>%
#  mutate(re_code = substr(name,7,7),
#         race = str_replace(concept,"SEX BY AGE \\(",""),
#         race = str_replace(race,"\\)",""),
#         age = str_replace(age, "Under 1 year", "0"),
#         age = str_replace(age,"year"," year"),
#         age = as.integer(substr(age,1,3))
#         ) %>%
#  filter(number_sams > 0, !is.na(age))
)

paste0("There are ",length(unique(trSARE_dec$age)), " unique categories for age (each year up to 100 and then two over 100 groups).")
paste0("There are ",length(unique(trSARE_dec$re_code)), " unique categories for race and ethnicity.")
paste0("Along with two categories for sex, we have ",length(unique(trSARE_dec$age))*length(unique(trSARE_dec$re_code))*2," different categories people can fall into.")
rm(trSAR_dec_data_from_census)
```

Point is that we have all these possible combinations, but they're embedded in the space in a way that makes them unequal. We have the weighting by potential intersections of functions - i.e., by partial differential equations - and the algebraic structure of possible combinations - the columns vs. the rows, first of all, but there's a logic to the columns and the rows and the ways in which the sampling from that space for the concepts has to do with what we mean by the individual unit of analysis. That the neighborhood has a structure that includes both the arithmetic and algebraic is part of the point.

We started with this file partly because it surprised us. Most of the files we worked with had separate tables for ethnicity and race, with no clear way of merging them. This one allows it.

Here are the further characteristics they offer:

```{r table for race and ethnicity types}
dt <- as.data.table(list(unique(trSARE_dec$re_code),unique(trSARE_dec$concept)))
setnames(dt, c("V1","V2"),c("re_code","concept"))
dt[order(concept)]
rm(dt)
```


Once we have the file for the entire population, we'll want to make one complete population with ethnicity and one complete population with race. It is worthwhile to take a second to think about what it means for the two representations of the entire population to be "equal" to each other. That they have the same number of people in each tract is part of the justification for saying they are equal but might be better phrased as saying that both tables are about the "same" people. There is also the way of saying they are equal because the schemas for classification have the same number of individuals in them, regardless of what you call the person in the particular category (i.e., "Hispanic" or "Latino" are treated as the same thing). And then, yet further, there is the sense in which the distinctions, and the combinations of the distinctions (i.e., what is called the power set produced by multiplying categories by each other) are equivalent if they divide the individuals considered as objects in the schema in the same way. That is, if you slice up the sets in different ways, but still come up with the same number of people in each cell, there's a certain type of "equality" there. To speak of "equality" in "ways of talking" is an attempt to make clear how mathematical objects, their structures, and the ways that their structures are conserved (or not) when moving between these "ways of talking" are all at stake even in fairly mundane classification tasks.

The fact that both the ethnicity tables and the race tables are about the same individuals, as presented in complete form through aggregations of individuals who have shared predicates, tells us that the "ways of talking about" those individuals are grounded in that sense of the individual. Some census tables don't share that same sense of individuality - some talk about households, for example, or about the housing stock - and yet there are still ways of delimiting the "sameness" of the tables - for instance, if they each talk about and characterize in some sense individual census tracts, which can be mapped back to individuals or other sorts of objects that can be counted, and can be considered the ground of saying that we're still talking about the same thing. This fact opens the door to talking about the relations that are mapped, with the individuals as endpoints of the mapping; to speak concretely about the relations first, and allowing the individuals to emerge into systems of possible relations, is the task we set ourselves with the construction of Sam City.

This table, we admit, caught us by surprise. All the other tables by race and ethnicity had only two ethnicities reported - one for "Hispanic or Latino," and another for "White Alone, not Hispanic or Latino." This led us to considerable difficulties in sorting out who might be, for example, answering "Some Other Race" and "Hispanic or Latino," or "Black or African American" and "Hispanic or Latino." These are admittedly smaller segments of the overall population, but important sectors to capture in the representation, if we are going to claim to understand details about the ways that race and ethnicity effect outcomes within the context of neighborhood dynamics. Even though we had been working extensively with the American Community Survey, we simply hadn't come across these tables. They don't solve all of our problems, but give information directly that will be of great value, below, and would have been very helpful in other contexts, earlier. Before getting to that very difficult question, we remember that at this point we're trying to understand how to maximize the information contained in overlapping ways of talking: how do we understand the addition of the idea of ethnicity on top of the idea of race? First, just be understanding in what sense it still refers to the same individuals and in what sense it constitutes new information.

Here, we're doing the expansion of race first, because in all the other tables, the race categorization is more "complete" than the representation by ethnicity. Which is to say that some people in the population are not represented in terms of their ethnicity, while everyone has their race reported. The sense in which the representation by race and by ethnicity are equal at the tract level, but not at the block_group level, gives us a chance to think about what it means for the representations to be embedded in conceptual spaces on rigorous mathematical terms, and to begin to see the ways that our representations are limited by those conceptual spaces as well as pointing to techniques that help us expand those representations. The equality of the representations come from the way in which they are structured by their endpoints as represented in a certain total number of individuals; it forces us not to think about the equality of two numbers in arithmetic, but the structure of embedding claims in the same underlying space. Taking another clue from recent turns in mathematics, we can say that it is, in certain conditions, equivalent to speak of the same individuals in different ways, to the extent that they both serve to describe the same individuals. The difference in describing those individuals by ethnicity instead of race emerges in the ways that the context of that designation matters, and not as a function of individuals essentially being in one set or another. The Census Bureau provides a helpful explanation, including the race iteration as [table ids explained](https://www.census.gov/programs-surveys/acs/guidance/which-data-tool/table-ids-explained.html)

```{r expand tract SAR}
race_codes <- c("A","B","C","D","E","F","G")
system.time(
    trSAR <- trSARE_dec %>%
      filter(re_code %in% race_codes) %>%
      uncount(number_sams,.id = "sams_race_id") #will create different id later
)
paste0("Total population in this representation is: ",nrow(trSAR))
```

Interestingly, because the total wasn't right the first time we processed this example, we were able to look for bugs in the code - in this case, not having noticed that there was an age called "Under 1 year" that needed to be made into a 0 to fit the pattern of the other ages (it's now fixed, above). There's a very practical side that drove us to triangulating - i.e., to checking things from multiple sides to see if they converged on the same answer - as well as the emerging understanding that moving between possible representations was itself a way of understanding how the objects of our inquiry were emerging as such.

We fixed that and then did one complete population for ethnicity: SET UP TABLE HERE FOR CODES, JUST LIKE DID FOR RACE; AND THEN SHOW THE AVERAGES ASSIGNED TO THE RACE, AND HOW THAT COMPARES TO THE GROUND TRUTH AT THE CENSUS LEVEL

```{r expand tract Harris SAE}
#one for Hispanic and then not Hispanic or Latino for each race; H and I do not match race codes in ACS
ethnicity_codes <- c("H","I","J","K","L","M","N","O") 
system.time(
trSAE <- trSARE_dec %>%
  filter(re_code %in% ethnicity_codes) %>%
  mutate(race = str_remove_all(race,", NOT HISPANIC OR LATINO")) %>%
  uncount(number_sams,.id = "sams_ethnicity_id") #will create different id later
)
paste0("Total population in this representation is: ",nrow(trSAE))
#which is conveniently the same as the totals above
nrow(trSAE)==nrow(trSAR)
#let's also clean up
trSAR <- as.data.table(trSAR)
trSAE <- as.data.table(trSAE)
rm(trSARE_dec)
```


This is, perhaps, still not as straightforward as one would like, because it gives us one part of a disjunctive syllogism and there are still potentially multiple categories on the other side of the disjunction (Hispanic with three races, for example). There is a table reported as part of the redistricting data (dec/pl in the API) that has separate categories for these combinations and for a large number of combinations for multi-racial individuals, but it does not give age at the same time and doesn't help with the difficult "SOME OTHER RACE ALONE." The ACS has tables for specific ethnicities and for multiple places of origin for ancestry, but they are not given in the decennial tables, and we can't match them exhaustively because of how the ACS is reported (and constructed). For the moment, we want to stick with the initial tables, and talk about how to construct our overall approach. In Harris County, 33% of the population were categorized as "Hispanic or Latino" in 2010, and 44% in 2020. Some individual census tracts are over 95% of one race or ethnicity. If we look at only race, we could get a very misleading sense of what the dynamics of a neighborhood were at the cultural level. So we wanted to somehow take the race tables, which had the virtue of a complete representation of all individuals, and add them to the ethnicity tables, which for the majority of tables are reported as only "White Alone, not Hispanic or Latino" and "Hispanic or Latino." 

In our initial naive approach, we had thought about creating a percentage of "Hispanic or Latino" for each race category compared to the tract total, and then just give every person in that race category an appropriate chance to be assigned "Hispanic or Latino" as their ethnicity. This clearly caused a great loss of information, however, as we wouldn't know how to distribute the odds by age and sex, except by creating more and more cells. Thinking more structurally helped, because it allows us to see that the distributions into the product space (the various cells) could be directly harnessed.

What we do, instead or treating it probabilistically, is to order each of the sets by their shared characteristics and assign an id, with numbers assigned sequentially for rows that match on all characteristics. We create the id by ordering the collections of properties in the same way for each set, and then assigning an id. The final sampled number in the id uses all the possible numbers between 1 and the number in that cell (the base r sample function defaults to "without replace"), so that all individuals are given a unique id but in a way that takes advantage of the many ways that the two sets can be ordered internally to find equivalent representations, which in turn allow for assigning properties that were not originally assigned in the given representations. That is, the structure of the production of the spaces was the same for the two tables - they have the same number of total cells - and the question is how to label them so they line up correctly. The attentive reader will note that there is no information lost here at the tract level, but that the ways in which race and ethnicity are joined at the block level could be lost. 

Perhaps talk about the genomics folks statement against using race as a marker?? Mike Fortun; just online...

We'll look at some of the relations in detail in the course of distributing non-White Hispanic or Latino ethnicity designations, but note immediately that very few people would have gone through the steps we just took to reconstruct those cross tabulations, even though the data is given. That the vast majority of people who answered "Some Other Race" were classified as "Hispanic or Latino" should give people pause for understanding what the composition of neighborhoods by race and ethnicity is really representing. [NPR article on "Some Other Race"](https://www.npr.org/2021/09/30/1037352177/2020-census-results-by-race-some-other-latino-ethnicity-hispanic) and [U.S. Census Bureau's explanation and tables](https://www.census.gov/library/stories/2021/08/improved-race-ethnicity-measures-reveal-united-states-population-much-more-multiracial.html), which includes a working paper, ["Race Reporting Among Hispanics: 2010"](https://www.census.gov/content/dam/Census/library/working-papers/2014/demo/shedding-light-on-race-reporting-among-hispanics/POP-twps0102.pdf). The working papers are relatively dense and strike a tone of neutrality, but are also used to justify and explain the process chosen by the Bureau, as opposed to arguing for change. The political questions are nested and thorny, of course, and one imagines that the bureaucratic stance is fully justified within the overarching political considerations of the production of the data tables. We are trying to fight against some of that bureaucratic framing, but only to understand how the choices resonate with the statistical and computational questions that are necessary precursors to using the data for analyses of social, economic, and health disparities.

In terms of the literal computations, we're doing a join, and some times the join could be done with one of the built-in merge functions in R or one of the R libraries. Here, because we want to emphasize the questions about the ordering and relations in terms of those orders, we make explicit the process of assigning numbers to each individual within a subset and then matching on those numbers to add variables across tables. As we move through the process, we'll find more precise control over the numbering within those final subtypes will matter.

```{r join trSAE and trSAR}
begin <- Sys.time()
trSAR[,("sar_match_id"):=
                    paste0(tract,sex,age,race,as.character(100000+sample(1:.N))),
                  by=.(tract,sex,age,race)]
trSAE[,("sar_match_id"):=
                    paste0(tract,sex,age,race,as.character(100000+sample(1:.N))),
                  by=.(tract,sex,age,race)]
trSAR[,("ethnicity"):=
                    trSAE[.SD, list(re_code), on = .(sar_match_id)]]
#By the disjunctive syllogism, the ones that don't match are the ones that are Hispanic
trSAR[is.na(ethnicity),("ethnicity"):="H"]
length(table(trSAR[re_code=="A",ethnicity]))==2
length(table(trSAR[re_code=="B",ethnicity]))==2
length(table(trSAR[,ethnicity]))==8
end <- Sys.time()
paste0("Time :",end-begin)
```

Just as we did by summing up the different ways that the total populations could be represented and then comparing the outputs to determine if the two representations are equal, we can use the table function from the base R library to get the number of people in each tract in the smallest cell created by combining factors (the power set). This will tell us if we successfully represented every person from the representation in terms of ethnicity in terms of race, with the same embedding in terms of tract, sex, and age. (Could put a little bit more on why that is better captured by types designating enclosing spaces than by set membership - although, importantly, both are possible, and equivalent for practical purposes within the current problem; in long run, the question is whether more complexity solves the problem, or if the construction can point to the proper levels of complexity)

```{r trSAE trSAR join tests}
test <- table(trSAR[,tract],
              trSAR[,sex],
              trSAR[,age],
              trSAR[,ethnicity]
)==table(
  trSAE[,tract],
  trSAE[,sex],
  trSAE[,age],
  trSAE[,re_code]
)
length(test[test==F])==0
#and test that the race codes still match for the non-Hispanic or Latino population
test <- table(trSAR[ethnicity!="H",race])==
  table(trSAE[race!="HISPANIC OR LATINO",race])
length(test[test==F])==0
```

For sake of completeness, we want to take the people who are over 100 and assign them single years of age, as well. We're going to be using SAR as our base for combinations, so we only do it on that one side. We're using sample with replace, so there will be a different size for the age by year every time the sampling is done. Since we want it to be reproducible, even at this level, we set the seed for the random number generator, so the random variation will be reproduced. There are only a handful of centenarians in the Harris County 2010 census and no reason to try to chase down more specifics in their true age distribution.

```{r centenarian age}
set.seed(Sam_seed)
trSAR[age==100,("age"):=sample(c(100,101,102,103,104),size = .N,replace = TRUE,prob = c(.29,.24,.19,.16,.12))]
trSAR[age==105,("age"):=sample(c(105:109),size = .N,replace = TRUE,prob = c(.29,.24,.19,.16,.12))]
trSAR[age==110,("age"):=sample(c(110:113),size = .N,replace = TRUE,prob = c(.6,.27,.1,.03))]
table(trSAR[age>100,age])
```

We know that it's fully commutative with the SAE file at the tract level, and that any specification to the block group would maintain that tract level commutativity, simply because the blocks are fully contained within the tract. We will find it helpful to draw some commutative triangles, as the tasks will get more and more complicated. In this, we just represent the fact that dividing the tables into one for ethnicity and one for race is still exhaustive on sex and age_range. We'll add more later. [Commutative Triangle: Tract level sex age race and ethnicity.](https://q.uiver.app/?q=WzAsNyxbMSwwLCJQQ1QxMlxcXFx0clNBUkUiXSxbMCwyLCJ0clNBUlxcXFxyYWNlXFxfN1xcO3hcXFxcc2V4XFw7eFxcO2FnZVxcXzExMCJdLFsyLDIsInRyU0FFXFxcXGV0aG5pY2l0eVxcXzhcXDt4XFxcXHNleFxcO3hcXDthZ2VcXF8xMTAiXSxbMSwxLCJ0b3RhbHNcXFxcc2FtZVxcO2J5XFxcXHRyYWN0XFw7YW5kXFxcXGNvbXBsZXRlXFw7YnlcXFxcYm90aFxcO3JhY2VcXDthbmRcXFxcZXRobmljaXR5Il0sWzEsMiwiXFxidWxsZXQiXSxbMiw0XSxbMCw0LCJ0clNBUlxcXFxyYWNlXFxfN1xcO3hcXFxcc2V4XFw7eFxcO2FnZVxcXzExMFxcXFxldGhuaWNpdHlcXF84Il0sWzAsMSwic3Vic2V0cyIsMSx7ImNvbG91ciI6WzEyMCw2MCw2MF19LFsxMjAsNjAsNjAsMV1dLFswLDIsInN1YnNldHMiLDEseyJjb2xvdXIiOlsxMjAsNjAsNjBdfSxbMTIwLDYwLDYwLDFdXSxbMSwyXSxbMiwxLCJjb21tdXRlcyJdLFszLDQsInRhYmxlcyA9IiwxLHsiY29sb3VyIjpbMzAwLDYwLDYwXX0sWzMwMCw2MCw2MCwxXV0sWzIsNiwiYWRkXFw7YnlcXFxcbWF0Y2hpbmciLDEseyJjb2xvdXIiOlsxMjAsNjAsNjBdfSxbMTIwLDYwLDYwLDFdXSxbMSw2XV0=)
Image: [Tract Sex Age Race and Ethnicity](trSARE.png)
Latex:
[\begin{tikzcd}
	& PCT12\\trSARE \\
	& {totals\\same\;by\\tract\;and\\complete\;by\\both\;race\;and\\ethnicity} \\
	{trSAR\\race\_7\;x\\sex\;x\;age\_110} & \bullet & {trSAE\\ethnicity\_8\;x\\sex\;x\;age\_110} \\
	\\
	{trSAR\\race\_7\;x\\sex\;x\;age\_110\\ethnicity\_8} && {}
	\arrow["subsets"{description}, color={rgb,255:red,92;green,214;blue,92}, from=1-2, to=3-1]
	\arrow["subsets"{description}, color={rgb,255:red,92;green,214;blue,92}, from=1-2, to=3-3]
	\arrow[from=3-1, to=3-3]
	\arrow["commutes", from=3-3, to=3-1]
	\arrow["{tables =}"{description}, color={rgb,255:red,214;green,92;blue,214}, from=2-2, to=3-2]
	\arrow["{add\;by\\matching}"{description}, color={rgb,255:red,92;green,214;blue,92}, from=3-3, to=5-1]
	\arrow[from=3-1, to=5-1]
\end{tikzcd}\]

Let's set this representation of the population aside for a moment and look at the block group level. We'll follow a very similar pattern, although there are small differences that make it impossible to run it simply through the same script. 


```{r expand bgSARE, warning = FALSE}
#2010 - bgSARE <- bgSAR_dec_data_from_census %>%
#  pivot_longer(4:ncol(bgSAR_dec_data_from_census),names_to = "geoid", values_to = "number_sams",
#                   names_transform = list(geoid=as.character)) %>%
#      separate(label, c("total","sex","age_range"), sep = "!!", remove = F, convert = FALSE) %>%
#      mutate(re_code = substr(name,5,5),
#             race = str_replace(concept,"SEX BY AGE \\(",""),
#             race = str_replace(race,"\\)",""),
#             age_range = str_replace(age_range,"Under 5 years","0  to  4 years"), 
#             age_range = str_replace(age_range,"5 to 9 years","05 to  9 years"),
#             age_range = str_replace(age_range,"18 and 19 years","18 to 19 years"),
#             age_range = str_replace(age_range,"20 years","20 to 20 years"),
#             age_range = str_replace(age_range,"21 years","21 to 21 years"),
#             age_range = str_replace(age_range,"85 years and over","85 to 110 years"),
#             age_range = str_replace(age_range,"and","to"),
#             first_age = as.integer(substr(age_range,1,2)),
#             last_age = as.integer(substr(age_range,7,8)),
#             tract = str_remove_all(geoid,"_"),
#             tract = substr(tract,1,11)
#             ) %>%
#      filter(number_sams > 0, !is.na(age_range))
begin <- Sys.time()
bgSARE_dec <- bgSAR_dec_data_from_census %>%
  pivot_longer(4:ncol(bgSAR_dec_data_from_census),names_to = "geoid", values_to = "number_sams",
                   names_transform = list(geoid=as.character)) %>%
  mutate(geoid = str_remove_all(geoid, "_")) %>%
  separate(label, c("total","sex","age_range"), sep = ":!!", remove = F, convert = FALSE) %>%
  mutate(re_code_eth = substr(name,4,4),
         re_code_sec = substr(name,5,5),
         race = str_replace(concept,"SEX BY AGE FOR SELECTED AGE CATEGORIES \\(",""),
         race = str_replace(race,"\\)",""),
         age_range = str_replace(age_range,"Under 5 years","0  to  4 years"), 
         age_range = str_replace(age_range,"5 to 9 years","05 to  9 years"),
         age_range = str_replace(age_range,"18 and 19 years","18 to 19 years"),
         age_range = str_replace(age_range,"20 years","20 to 20 years"),
         age_range = str_replace(age_range,"21 years","21 to 21 years"),
         age_range = str_replace(age_range,"85 years and over","85 to 110 years"),
         age_range = str_replace(age_range,"and","to"),
         first_age = as.integer(substr(age_range,1,2)),
         last_age = as.integer(substr(age_range,7,9)),
         tract = str_remove_all(geoid,"_"),
         tract = substr(tract,1,11)
         ) %>%
  filter(number_sams > 0, !is.na(age_range))
end <- Sys.time()
paste0("Time: ",end-begin)
rm(bgSAR_dec_data_from_census)
```

Now we filter and construct distinct tables by race and ethnicity codes. They changed the tables significantly in 2020, and we can use some of the new categories to check our work with bgSARE. 
Let's look at the categories first:
```{r table for race and ethnicity concepts}
dt <- as.data.table(list(unique(bgSARE_dec$re_code_sec),unique(bgSARE_dec$concept)))
setnames(dt, c("V1","V2"),c("re_code_sec","race"), skip_absent = TRUE)
dt[order(race)]
rm(dt)
```


```{r SAR expand to bg}
start <- Sys.time()
#race_codes <- c("A","B","C","D","E","F","G") #they completely changed the names for 2020!!!
bgSARE <- bgSARE_dec %>%
  filter(str_detect(race,"LATINO"),!str_detect(race,"COMBINATION"),race!="HISPANIC OR LATINO") %>%
  uncount(as.numeric(number_sams),.id = "sams_race_id")
bgSARE <- as.data.table(bgSARE)
end <- Sys.time()
paste0("Process took ",end-begin," to finish creating set")
paste0("Total population in bgSARE representation is: ",nrow(bgSARE))
#which is also the same as the totals above
nrow(bgSARE)==nrow(trSAR)
# for 2010
#bgSAR <- bgSARE_dec %>%
#  filter(re_code %in% race_codes, re_code_sec=="_") %>%
#  uncount(number_sams,.id = "sams_race_id")
#bgSAR <- as.data.table(bgSAR)
#paste0("Total population in bgSAR representation is: ",nrow(bgSAR))
##which is also the same as the totals above
#nrow(bgSAR)==nrow(trSAR)
rm(bgSARE_dec)
```

Let's put in ethnicity codes for bgSAE and expand, so that the tables from tract and block group match as far as possible, even if we don't know all the demographic specifics (age by year and race of non-White Hispanics) that had been available at the tract level. Notice that the population totals do not match; the ethnicity description is not complete for the population as it had been for race at the block group and for both race and ethnicity at the tract levels. We will have to account for that structuring choice in how the tables are reported in order to construct our own complete representation for the simulation.

```{r SAE expand to bg}
#only for 2010
#eth_codes <- c("H","I")
#bgSAE <- bgSARE %>%
#  filter(re_code %in% eth_codes) %>%
#  uncount(number_sams,.id = "sams_race_id")
#bgSAE <- as.data.table(bgSAE)
#paste0("Total population in this representation is: ",nrow(bgSAE))
##see if age_ranges line up, because sometimes they do not between ethnicity and race reporting by the Census Bureau
#test <- sort(unique(bgSAE$age_range))==sort(unique(bgSAR$age_range))
#length(test[test==FALSE])==0
#rm(bgSARE)
```

Part of what's interesting, here, is that the tract level wanted to keep straight all the potential Hispanic or Latino combinations - for example, Black Hispanic is not listed in the block_group, but is available in the tract (albeit by disjunction). At the tract level, you have both "BLACK OR AFRICAN AMERICAN ALONE" and "BLACK OR AFRICAN AMERICAN ALONE, NOT HISPANIC OR LATINO"), which is what lets you impute Black and Hispanic from the remainder. Tract level reporting did not include that extra level. The race_ethnicity codes (re_code) for ethnicity is only either H or I at the block group level.

```{r table eth_codes}
#dt <- as.data.table(list(unique(bgSAE$re_code),unique(bgSAE$race)))
#setnames(dt, c("V1","V2"),c("re_code","concept"))
#dt[order(re_code)]
#rm(dt)
```

This means that the only information we know at the block group level is the number of people who are "Hispanic or Latino" and the number who are "White Alone, Not Hispanic or Latino." By the disjunctive syllogism, we can know the number of "Not White Alone "Hispanic or Latino," which will include all the subtypes available at the tract level in table PCT12.  Because we do know their sex and age_group, we can add them to the block_group by race representation on White Alone (which, in the race representation, includes many, but not all, of the Hispanic or Latino population). Since no other information is known about the individuals, we are constructing a representation that will not lose the structures of any of the originating embeddings, as reported. As we add more contexts to construct a more complicated description of the population, that task will become more difficult (and more interesting). This example is one of the simpler versions, and is not controversial. 

REDO AS POWER SET: We note, also, that the two tables are not commutative in the way that the tract level was, because the total populations are not the same, but that the subsets for the White population are knowable. We can draw it, echoing our drawing above, [block group race and ethnicity](https://q.uiver.app/?q=WzAsNixbMSwwLCJQMTJcXFxcYmdTQVJFIl0sWzAsMiwiYmdTQVJcXFxccmFjZVxcXzdcXDt4XFxcXHNleFxcO3hcXDthZ2VcXF8yMyJdLFsyLDIsImJnU0FFXFxcXGV0aG5pY2l0eVxcXzJcXDt4XFxcXHNleFxcO3hcXDthZ2VcXF8yMyJdLFsxLDEsInRvdGFsc1xcXFxkaWZmZXJlbnRcXDtieVxcXFx0cmFjdFxcO2FuZFxcXFxvbmx5XFw7b3ZlcmxhcFxcXFxvblxcO3JhY2VcXDthbmRcXFxcZXRobmljaXR5Il0sWzEsMiwiXFxidWxsZXQiXSxbMiw0XSxbMCwxLCJzdWJzZXRzIiwxLHsiY3VydmUiOjEsImNvbG91ciI6WzEyMCw2MCw2MF19LFsxMjAsNjAsNjAsMV1dLFswLDIsInN1YnNldHMiLDEseyJjdXJ2ZSI6LTEsImNvbG91ciI6WzEyMCw2MCw2MF19LFsxMjAsNjAsNjAsMV1dLFsxLDJdLFsyLDEsImRvZXNcXDtub3RcXFxcY29tbXV0ZSIsMCx7ImNvbG91ciI6WzQsOTcsNjBdfSxbNCw5Nyw2MCwxXV0sWzMsNCwidGFibGVzIFxcbmVxIiwxLHsiY29sb3VyIjpbNCw5Nyw2MF19LFs0LDk3LDYwLDFdXV0=) 
[Block Group Sex Age Race Ethnicity](bgSARE.png)
LaTeX: 
[\begin{tikzcd}
	& P12\\bgSARE \\
	& {totals\\different\;by\\tract\;and\\only\;overlap\\on\;race\;and\\ethnicity} \\
	{bgSAR\\race\_7\;x\\sex\;x\;age\_23} & \bullet & {bgSAE\\ethnicity\_2\;x\\sex\;x\;age\_23} \\
	\\
	&& {}
	\arrow["subsets"{description}, color={rgb,255:red,92;green,214;blue,92}, curve={height=6pt}, from=1-2, to=3-1]
	\arrow["subsets"{description}, color={rgb,255:red,92;green,214;blue,92}, curve={height=-6pt}, from=1-2, to=3-3]
	\arrow[from=3-1, to=3-3]
	\arrow["{does\;not\\commute}", color={rgb,255:red,252;green,67;blue,54}, from=3-3, to=3-1]
	\arrow["{tables \neq}"{description}, color={rgb,255:red,252;green,67;blue,54}, from=2-2, to=3-2]
\end{tikzcd}\]

As an aside that we will take up more at length, later, the race is allocated by the census taker (or sometimes an automated process) when the surveyed person refuses to give a race (or if the answer given doesn't agree with the algorithms). For the 2010 census, that activity was reported under the table, "Allocation of Race" (P46). There's not much we can do to dive into the detail about why it happened, except to note that a fairly large percentage had to be allocated, and that it was quite variable by tract. Deciding whether there is a source of error also depends on whether the ground truth would be the individual's self-designation, assuming they trusted the census-taker enough to tell them the truth, or whether there is an objective (or objectively consistent) designation that should be followed for the classification. For example, a person who prefers to be called "Latinx" would be grouped with "Hispanic or Latino" in this approach, and the political differences that were already inherent in "Hispanic" vs. "Latino" were collapsed into an awkward category that just had both names, just as "Black or African American" collapses many important distinctions about how people self-identify.[https://news.gallup.com/poll/353000/no-preferred-racial-term-among-black-hispanic-adults.aspx] The technical details for the Census Bureau's own framework can be found here: https://www.socialexplorer.com/data/C2010/metadata/?ds=SF1&table=P0460, but we will also have a more detailed conversation, below. The important thing to note is that the Census Bureau tried to conserve structures of consistency and completeness by carefully articulating rules for the data collection and ensuring that everyone fit into some category. This concern for consistency and completeness is completely justified, given the goals of the census, but we should be attentive to the other structures of representation that are not conserved but could have been, including people's right to self-identification, genetic profiles, either patrilineal or matrilineal descent, adoptive or biological descent, or self-identification with particular cultural tropes or characters from popular culture. Then, at the limit, what things are not amenable to this sort of "naming" should also be articulated explicitly, so that we can construct better ways of talking about the world than just more and more complicated names attached to individuals. 

For instance, in the tract tables, we see that there is a category for "SOME OTHER RACE ALONE" (re_code=="F") that has 583,566 people in it. Of those people, fewer than 8,000 were listed as "NOT HISPANIC OR LATINO" - just over 1%. Similarly, "TWO OR MORE RACES" (with 131,332 total and re_code=="G") has more than 60% (82494) listed as "HISPANIC OR LATINO."  Do we really imagine that the designations make the same sense to the people who are talking about themselves as it does to the Census Bureau? This table shows the cross-tabs for race and ethnicity, where not "H" indicates that they are the race listed, but "NOT HISPANIC OR LATINO."

```{r table for race and ethnicity and test for zeros}
test_table <- table(trSAR$re_code,trSAR$ethnicity)
test_table
length(test_table[test_table==0])==
  length(table(trSAR$ethnicity))*length(table(trSAR$re_code))-
  (length(table(trSAR$re_code))*2)
```

For now, we want to focus on the prosaic process of construction. To read the data.table script, below, you'd say that for the rows in bgSAR that match the White only group (re_code=="A"), assign a match_id with the components of tract, sex, age, and an appropriate random number chosen between 1 and the total number of individuals in that subgroup (the default is replace=FALSE, which is to say that all those numbers are assigned). Then you do the same for bgSAE. Then the folks left in each tract in the category of Hispanic or Latino should be more than the number of White Alone that are left (presumably that portion of the Hispanic population was listed as some other racial category).

With these caveats in mind, let's look at how to best move the detailed tract data onto the block_group, with some discussion of other approaches and inherent dangers to the representations. We begin with the joins on ethnicity and race that are available at the block_group level. An overall view of the first two steps, as we join what is known, can be drawn: [Add White Ethnicity to Race Tables by Block Group](https://q.uiver.app/?q=WzAsOSxbMSwwLCJiZ1NBUlxcXFxyYWNlXFxfN1xcO3hcXFxcc2V4XFw7eFxcO2FnZVxcXzIzIl0sWzMsMCwiYmdTQUVcXFxcZXRobmljaXR5XFxfMlxcO3hcXFxcc2V4XFw7eFxcO2FnZVxcXzIzIl0sWzMsMl0sWzEsMiwiV2hpdGVcXDtBbG9uZSxcXFxcbm90XFw7SGlzcGFuaWNcXFxcb3JcXDtMYXRpbm8iXSxbMSw0LCJXaGl0ZVxcO0Fsb25lLFxcXFxIaXNwYW5pY1xcXFxvclxcO0xhdGlubyJdLFszLDUsImJnU0FFXFxcXGV0aG5pY2l0eVxcXzJcXDt4XFxcXHNleFxcO3hcXDthZ2VcXF8yM1xcXFx4XFw7cmFjZVxcXzEiXSxbMSw1LCJiZ1NBUlxcXFxyYWNlXFxfN1xcO3hcXFxcc2V4XFw7eFxcO2FnZVxcXzIzXFxcXHhcXDtldGhuaWNpdHlcXF8xLjUiXSxbMCw1LCJOb3RcXDtXaGl0ZSxcXFxcSGlzcGFuaWNcXDtvclxcXFxMYXRpbm9cXFxcbm90XFw7a25vd24iLFswLDYwLDYwLDFdXSxbMSw2LCJjb3VudFxcO0hpc3BhbmljXFxcXG9yXFw7TGF0aW5vXFxcXHJlbWFpbmluZ1xcXFx4XFw7YmxvY2tcXDtncm91cFxcXFx4XFw7c2V4XFw7eFxcO2FnZSJdLFsxLDMsIkV0aG5pY2l0eT09IElcXFxcbWF0Y2hcXFxcc2V4XFw7eFxcO2FnZSIsMV0sWzAsMywicmFjZT09QSIsMV0sWzMsNCwiQnlcXDtkaXNqdW5jdGlvblxcXFxyZW1haW5pbmdcXFxcYXJlOiIsMV0sWzEsNV0sWzQsNSwibWF0Y2hcXFxcc2V4XFw7eFxcO2FnZSIsMV0sWzQsNl0sWzYsOF1d)
[Image](bgSARnwhlnk.png)
LaTeX: 
[\begin{tikzcd}
	& {bgSAR\\race\_7\;x\\sex\;x\;age\_23} && {bgSAE\\ethnicity\_2\;x\\sex\;x\;age\_23} \\
	\\
	& {White\;Alone,\\not\;Hispanic\\or\;Latino} && {} \\
	\\
	& {White\;Alone,\\Hispanic\\or\;Latino} \\
	\textcolor{rgb,255:red,214;green,92;blue,92}{Not\;White,\\Hispanic\;or\\Latino\\not\;known} & {bgSAR\\race\_7\;x\\sex\;x\;age\_23\\x\;ethnicity\_1.5} && {bgSAE\\ethnicity\_2\;x\\sex\;x\;age\_23\\x\;race\_1} \\
	& {count\;Hispanic\\or\;Latino\\remaining\\x\;block\;group\\x\;sex\;x\;age}
	\arrow["{Ethnicity== I\\match\\sex\;x\;age}"{description}, from=1-4, to=3-2]
	\arrow["{race==A}"{description}, from=1-2, to=3-2]
	\arrow["{By\;disjunction\\remaining\\are:}"{description}, from=3-2, to=5-2]
	\arrow[from=1-4, to=6-4]
	\arrow["{match\\sex\;x\;age}"{description}, from=5-2, to=6-4]
	\arrow[from=5-2, to=6-2]
	\arrow[from=6-2, to=7-2]
\end{tikzcd}\]

```{r join bgSAE and bgSAR}
#NEED FOR 2010, but not 2020
#bgSAR[re_code=="A",("sar_match_id"):=
#                    paste0(geoid,sex,age_range,as.character(100000+sample(1:.N))),
#                  by=.(geoid,sex,age_range)]
#bgSAE[re_code=="I",("sar_match_id"):=
#                    paste0(geoid,sex,age_range,as.character(100000+sample(1:.N))),
#                  by=.(geoid,sex,age_range)]
#bgSAR[re_code=="A",("ethnicity"):=
#                    bgSAE[.SD, list(re_code), on = .(sar_match_id)]]
##move back to SAE, so we can track sex and age_range combinations that have been eliminated
#bgSAE[re_code=="I",("r_code"):=
#                    bgSAR[.SD, list(re_code), on = .(sar_match_id)]]
#nrow(bgSAR[!is.na(ethnicity)&re_code=="A"])==nrow(bgSAE[re_code=="I"])
#nrow(bgSAE[re_code=="I"])==nrow(bgSAE[!is.na(r_code)])
#test <- table(bgSAR[re_code=="A"&!is.na(ethnicity),geoid],
#              bgSAR[re_code=="A"&!is.na(ethnicity),sex],
#              bgSAR[re_code=="A"&!is.na(ethnicity),age_range]
#) == table(
#  bgSAE[re_code=="I",geoid],
#  bgSAE[re_code=="I",sex],
#  bgSAE[re_code=="I",age_range]
#)
#length(test[test==FALSE])==0
#all the individuals who identify as both White and Hispanic or Latino are accounted for
```

Having assigned the part of the population that we know to be White Alone, Not Hispanic or Latino at the block group level, we can now give the White Alone, Hispanic or Latino an "H" for ethnicity and mark off the Hispanics in the ethnicity block group tables by those sex and age_ranges. Since the groups are complements of each other (in fact, adjoint), and there are only a few things ascribed to each table, the subsetting can be done without loss of information. 

```{r assign rest of White alone ethnicity and do counts for Hispanic or Latino remaining in block}
#bgSAR[is.na(ethnicity)&re_code=="A",("ethnicity"):="H"]
##put a marker back on SAE, so that age and sex for the others stays same
#bgSAR[re_code=="A"&ethnicity=="H",("sar2_match_id"):=
#                    paste0(geoid,sex,age_range,as.character(100000+sample(1:.N))),
#                  by=.(geoid,sex,age_range)]
#bgSAE[re_code=="H",("sar2_match_id"):=
#                    paste0(geoid,sex,age_range,as.character(100000+sample(1:.N))),
#                  by=.(geoid,sex,age_range)]
#bgSAE[re_code=="H",("r_code"):=
#                    bgSAR[.SD, list(re_code), on = .(sar2_match_id)]]
##check all moved over for White Alone rows
#nrow(bgSAE[!is.na(r_code)])==nrow(bgSAR[re_code=="A"])
##Now let's do some tests first to ensure we've got what we think we have
#nrow(bgSAR[ethnicity!="I"&re_code=="A"])==nrow(trSAR[ethnicity!="I"&re_code=="A"])
#nrow(bgSAR[is.na(ethnicity)&re_code=="A"])==0
##SAE_Harris (tract) for just H and I has the same total size as bgSAE for blocks.
#nrow(trSAE[re_code%in%c("H","I")])==nrow(bgSAE)
##check that White Alone has right number totals on both sides
#nrow(bgSAE[re_code=="H"&!is.na(r_code)])+nrow(bgSAE[re_code=="I"])==
#  nrow(bgSAR[re_code=="A"])
#
##move number of total non-White Hispanic or Latino onto all rows in block by sex and age_range
#bgSAE[is.na(r_code),("H_block"):=.N,by=.(geoid,sex,age_range)]
#bgSAE[is.na(r_code),("H_tract"):=.N,by=.(tract,sex,age_range)]
#bgSAR[re_code!="A",("sar3_match_id"):=
#                    paste0(geoid,sex,age_range,as.character(100000+sample(1:.N))),
#                  by=.(geoid,sex,age_range)]
#bgSAE[is.na(r_code),("sar3_match_id"):=
#                    paste0(geoid,sex,age_range,as.character(100000+sample(1:.N))),
#                  by=.(geoid,sex,age_range)]
#bgSAR[re_code!="A",c("H_block"):= 
#                    bgSAE[.SD, list(H_block), on = .(sar3_match_id)]]
#summary(bgSAR[,H_block])==summary(bgSAE[,H_block]) #should be TRUE for all except NA's
#nrow(bgSAE[!is.na(H_block)])==nrow(bgSAR[!is.na(H_block)])
##put the number remaining Hispanic or Latino by block group, sex, and age_range on every row in SAR without ethnicity
#bgSAR[is.na(H_block),("H_block"):=0] #something about .SD working with NAs is funky
#bgSAR[order(-H_block),("bg_H_remain"):=.SD[1,H_block], #should be only one number per group, but don't know what row it's in
#         by=.(geoid,sex,age_range)]
##some summaries and tests
#paste0("number of Hispanic or Latino who are not White alone: ",
#       nrow(bgSAE)-nrow(bgSAR[!is.na(ethnicity)]))
##which should equal the same in the tract table
#nrow(trSAR[ethnicity=="H"])-nrow(trSAR[re_code=="A"&ethnicity=="H"])==
#  nrow(bgSAE)-nrow(bgSAR[!is.na(ethnicity)])
##the ones who are neither H nor I are all the non-White categories minus the Hispanics
#H_A <- nrow(bgSAR[ethnicity=="H"&re_code=="A"])
#paste0("The number of people listed as White by race and Hispanic or Latino by ",
#       "ethnicity at the block level, ",
#       H_A,", should equal the total from tracts")
#H_A==nrow(trSAR[re_code=="A"])-nrow(trSAR[ethnicity=="I"])
##which means the complete White population has ethnicity assigned
#paste0("This leaves ",nrow(bgSAE[re_code=="H"]) - H_A," non-White, Hispanic or Latino,",
#       " out of ",nrow(bgSAR[re_code!="A"])," non-White individuals. Of that remaining Hispanic or Latino population, ", #nrow(trSAR[re_code=="F"&ethnicity=="H"]), 
#       " consider themselves Some Other Race Alone")
##also check to see that the number of non-White Hispanic or Latino matches
#nrow(trSAR[ethnicity=="H"&re_code!="A"])==nrow(bgSAE[is.na(r_code)])
```

We can add in the tract data at this point, matching on ethnicity, with race assigned within the subgroups where we don't know ethnicity by random sample, but there's a potential that some of the folks (1,774,203) who don't have ethnicity assigned at the block group will be misassigned within the tract to the wrong block group. We've been able to identify non-White Hispanic or Latino individuals (702,930), but don't know how they distribute by race by block group (only by tract). That is, we can easily create a commutative representation grounded in both race and ethnicity at the tract level, but it might break with other commutative relations at other levels that depend on how race is combined with ethnicity at the block group level. 

We have each race x age total and each race x age, non-Hispanic at tract - so know Hispanic by disjunction at tract, but not what individuals to attach them to at the block group. This is a recurring issue for later, of course, and we can't just ignore it. The temptation is to add the tract and group level data together and just accept the lost information. We have a bit more information in our existing tables to account for, though, and some other sources for triangulation. We know how many people are Hispanic in each block group, which means that we also know how many are non-Hispanic, but we don't know which races should also be listed as Hispanic. We do know where races are by block group, however. We could estimate by calculating the statistical likelihood of race x ethnicity x age for each race at the tract level and assigning it to each race x age at the block level. Surely better than a simple random distribution - it takes into account some strong priors - it still favors the individual calculation of likelihood to encounter an individual with certain characteristics instead of maintaining the structure of relations between race and ethnicity at the block group level. If, instead, we think of every relation at the tract level as given, so there is a total number of people with each combination of race x ethnicity x age at the tract level, and we know the White populations distribution at the block level, what you have is not the percentage that are in each block group, but the actual number that the block group provides, and our issue is to distribute them. 

[Assigning Hispanic or Latino for non-White Population by Block and Tract](https://q.uiver.app/?q=WzAsMTIsWzEsMCwiYmdTQVJcXFxccmFjZVxcXzdcXDt4XFxcXHNleFxcO3hcXDthZ2VcXF8yMyJdLFszLDAsImJnU0FFXFxcXGV0aG5pY2l0eVxcXzJcXDt4XFxcXHNleFxcO3hcXDthZ2VcXF8yMyJdLFszLDJdLFsxLDIsIldoaXRlXFw7QWxvbmUsXFxcXG5vdFxcO0hpc3BhbmljXFxcXG9yXFw7TGF0aW5vIl0sWzEsNCwiV2hpdGVcXDtBbG9uZSxcXFxcSGlzcGFuaWNcXFxcb3JcXDtMYXRpbm8iXSxbMyw1LCJiZ1NBRVxcXFxldGhuaWNpdHlcXF8yXFw7eFxcXFxzZXhcXDt4XFw7YWdlXFxfMjNcXFxceFxcO3JhY2VcXF8xIl0sWzEsNSwiYmdTQVJcXFxccmFjZVxcXzdcXDt4XFxcXHNleFxcO3hcXDthZ2VcXF8yM1xcXFx4XFw7ZXRobmljaXR5XFxfMS41Il0sWzAsNSwiTm90XFw7V2hpdGUsXFxcXEhpc3BhbmljXFw7b3JcXFxcTGF0aW5vXFxcXG5vdFxcO2tub3duIixbMCw2MCw2MCwxXV0sWzEsNiwiY291bnRcXDtIaXNwYW5pY1xcXFxvclxcO0xhdGlub1xcXFxyZW1haW5pbmdcXFxceFxcO2Jsb2NrXFw7Z3JvdXBcXFxceFxcO3NleFxcO3hcXDthZ2UiXSxbMiw2LCJjb3VudFxcO2lzXFxcXHJlc3VsdFxcO29mXFxcXHN0cnVjdHVyZVxcXFxvblxcO2Fkam9pbnRcXFxcc2lkZSIsWzAsNjAsNjAsMV1dLFszLDYsImJsb2NrXFw7c3RydWN0dXJlXFxcXHdpdGhpblxcXFx0cmFjdHNcXFxcY3JlYXRlc1xcXFxkaXN0cmlidXRpb24iXSxbMSw3LCJ0cmFjdFxcO2xldmVsXFxcXGdpdmVzXFxcXGluZGl2aWR1YWxcXFxcdmFsdWVzXFxcXGRpc3RyaWJ1dGVkXFxcXHdpdGhcXDtzdHJ1Y3R1cmUiXSxbMSwzLCJFdGhuaWNpdHk9PSBJXFxcXG1hdGNoXFxcXHNleFxcO3hcXDthZ2UiLDFdLFswLDMsInJhY2U9PUEiLDFdLFszLDQsIkJ5XFw7ZGlzanVuY3Rpb25cXFxccmVtYWluaW5nXFxcXGFyZToiLDFdLFsxLDVdLFs0LDUsIm1hdGNoXFxcXHNleFxcO3hcXDthZ2UiLDFdLFs0LDZdLFs2LDhdLFs4LDExLCJkZXRlcm1pbmUiLDFdXQ==)
[Hispanic or Latino Count](Hispanic or Latino Count.png)

The idea is that you want the values to have been determined by the structure provided from both sides, with the values assigned from the one that constrains toward the individual values. [[it's a weird question about what the precise language should be]] Perhaps it's more like the idea that you have channels, like sieves, that come from different structures, but attach to the row as it passes through the alluvial. 

What we mean by structure is embodied in how the names can circulate in relation to the named - not the Kantian (as diagnosed by Sellars) moment of simple and single contact with the noumenal, but a channel within which the names circulate according to a structure. That is, we are not trying to find a place where the name is correct, but where the names have a logic of application and the structure that makes that application make sense is captured. This allows for the movement between different ways of naming to make sense. Here, we do it one at a time, so that the determination from the ethnicity as given in the table for tracts has the relation to race moved over from the block group tables. When we match block and ethnicity from the block group level for the group quarters, below, we are combining the two structured ways of naming by capturing how one moves between them. As we find more difficult situations, that sense of movement will allow us to speak to the sense of a dynamic dialogue between different ways of naming that demonstrates more capacity for eliciting and understanding structures. We are not trying to become relativists by refusing the idea of naming as the place where a truth is instantiated, but showing that ways of naming allow us to see structures that encompass multiple strategies for structuring how the names are attached, and to see the comparison in algebraic or topological terms (as ways of combining structures) and not as a single action of determination in an individual's act of naming what is as the result of an act of naming from a determined perspective on the whole. The structure for ethnicity by race is highly determinative for "Some Other Race" (almost 99% in Harris County), but not exhaustive, and just less than two-thirds for "Two or More Races," with a large cohort for "Black or African American" and "Hispanic or Latino" (21,234 people, which is just less than 3% of all "Black or African American").  



```{r add age from trSAR so that it matches}
#if I just make a new re_code, is there some possibility of not matching?
#> unique(bgSARE[re_code_eth=="P",race])
#[1] "WHITE ALONE, HISPANIC OR LATINO"
#> unique(bgSARE[re_code_eth=="Q",race])
#[1] "BLACK OR AFRICAN AMERICAN ALONE, HISPANIC OR LATINO"
#> unique(bgSARE[re_code_eth=="R",race])
#[1] "AMERICAN INDIAN AND ALASKA NATIVE ALONE, HISPANIC OR LATINO"
#> unique(bgSARE[re_code_eth=="S",race])
#[1] "ASIAN ALONE, HISPANIC OR LATINO"
#> unique(bgSARE[re_code_eth=="T",race])
#[1] "NATIVE HAWAIIAN AND OTHER PACIFIC ISLANDER ALONE, HISPANIC OR LATINO"
#> unique(bgSARE[re_code_eth=="U",race])
#[1] "SOME OTHER RACE ALONE, HISPANIC OR LATINO"
#> unique(bgSARE[re_code_eth=="V",race])
#[1] "TWO OR MORE RACES, HISPANIC OR LATINO"
#> unique(bgSARE[re_code_eth=="I",race])
#[1] "WHITE ALONE, NOT HISPANIC OR LATINO"
#> 
#> #adding in each year doesn't make much difference, but serves the same purpose of making it individuated.
bgSARE[,("re_code"):=fcase(re_code_eth=="I","A",
                            re_code_eth=="P","A",
                            re_code_eth=="J","B",
                            re_code_eth=="Q","B",
                            re_code_eth=="K","C",
                            re_code_eth=="R","C",
                            re_code_eth=="L","D",
                            re_code_eth=="S","D",
                            re_code_eth=="M","E",
                            re_code_eth=="T","E",
                            re_code_eth=="N","F",
                            re_code_eth=="U","F",
                            re_code_eth=="O","G",
                            re_code_eth=="V","G")]
bgSARE[order(tract,first_age),("age_match_id"):=
                    paste0(tract,sex,re_code,as.character(100000+seq.int(1:.N))),
                  by=.(tract,sex,re_code)]
trSAR[order(tract,age),("age_match_id"):=
                    paste0(tract,sex,re_code,as.character(100000+seq.int(1:.N))),
                  by=.(tract,sex,re_code)]
bgSARE[,("age"):=
                    trSAR[.SD, list(age), on = .(age_match_id)]]
test <- table(bgSARE[,tract],
              bgSARE[,sex],
              bgSARE[,re_code],
              bgSARE[,age]
              )==
        table(trSAR[,tract],
              trSAR[,sex],
              trSAR[,re_code],
              trSAR[,age]
              )
length(test[test==FALSE])==0
```

FIGURE OUT WHICH ONES TO CLEAN AND THEN SAVE

```{r clean up bgSAR and extra files}
rm(trSAE)
rm(trSAR)
bgSARE[,c("name","label","total","concept","sams_race_id","age_match_id"):=NULL]
```


```{r save working bgSARE}
if (file.exists(paste0(censusdir,vintage,"/working/bgSARE.RDS"))){
  file.remove(paste0(censusdir,vintage,"/working/bgSARE.RDS"))
}
if (file.exists(paste0(censusdir,vintage,"/working"))){
    print(sprintf("found folder %s", paste0(censusdir,vintage,"/working")))
    saveRDS(bgSARE,paste0(censusdir,vintage,"/working/bgSARE.RDS"))
  }else{
    dir.create(paste0(censusdir,vintage,"/working"))
    print(sprintf("created folder %s", paste0(censusdir,vintage,"/working")))
    saveRDS(bgSARE,paste0(censusdir,vintage,"/working/bgSARE.RDS"))
  }

```



Continue with making_sam_bg_hh, for Texas; remember to delete the Harris only files...

For 2010 decennial, need pieces from making_sam

Could quickly add P1 and P2, in order to get more detail for two or more races, which is in context_unit - .

For the decennial 2020: https://www2.census.gov/programs-surveys/decennial/2020/technical-documentation/complete-tech-docs/summary-file/2020Census_PL94_171Redistricting_StatesTechDoc_English.pdf




Somewhere above, about Type theory and computability - the only operations allowed to do the matching are things that you can place on a single row and then can match with a different table uniquely by that row. That is a complement or adjoint of the sense of complementarity itself.... You can give a whole group a name, and then count each individual, and you can do things that allow you to count multiple times as you subset, but each individual has to be somehow given a value, so that the row can be assessed. That this is also part of what drives imperative programming and nominalistic epistemology to think that the task is to test whether a name is correctly used as opposed to asking what patterns emerge. (think of difference between adding in imperative and functional languages, or in Peano vs. Church, and the order of calculation; and then how that means that our question, here, is different). Part of the difficulty is that the factors being assigned are slightly different than the cartesian product of possible assignments - could tease that out, above.



NOTES:
In a broad sense, we're asking - at a practical level - what's it mean to use .map on the construction of epidemiology's domain and co-domain as explicitly about how we talk about vs. how relations build on each other. Not the convergence toward a single perspective, but toward a shared commitment to speaking about what matters in the relations.

For restructuring of argument part - that the construction "from the outside" of the type theory lets you resolve the arguments without positing the consistency of the inside as given - you don't have to believe the axiom of reducibility or that there is a zero-degree homotopy (should we try to show that things like that are equal?)

Plan: find smallest units of "space" (geographic and/or conceptual) from decennial census and build a cohesive representation of Harris County (called Sam City) by piecing together the various representations output by the census. 

Somewhere - that there are a few different metaphors one might use for how a table relates to a full population. One can think of it as a sample, or a sample of a sample, as a view on a pivot table, or a kind of literal movement of markers for real things into bins of some sort, counting the predicates. That, instead, we wish to see it as a way of structuring an account that responds to what one is trying to show (or to hide) and how one constructs a cohesive space within which the important other relations will hold (and we can do arithmetic and summarization, etc.). It's also important that at that point, you're not talking about ways of naming individuals and then aggregating over that name, but that you're talking about ways of talking about collections, and how names are distributed within that space - so there's a subsetting logic, even if you name the whole population, if you're only talking about them in terms of one way of talking. 

By selection, we mean choosing one way of speaking about the population as opposed to another. You are selecting within the power set of all the combined ways of talking, which can exclude whole people from being spoken of at all, or can cause some people to be spoken of in two ways - the example we'll dive into in-depth is race and ethnicity. To select only "children" is then also to select by a way of talking, so that selecting the category of humans under 18 years of age is different than to select the households where a biological child of the householder is present. The way we want to approach this, mathematically, is to record the choices and see what other tools rebound to our use because of those choices. If you've made a selection, after all, you've introduced a distinction into the set that has both what is included and what is excluded. You've also introduced a way of producing individuals "as" either included or excluded. There are tools available to us that take what we know about the included to talk about the excluded, or to talk about the process of producing inclusion or exclusion, and how one might modify a given process to produce different results.

By "space" we mean something that helps situate a characterization within a structure, not the placement of an individual thing within a bunch of other individual things that happen to be "close" in some assigned sense of distance. A context is an example of a distance-based space, as your neighborhood provides context for your dwelling, but part of the point of our exercise with Sam City is to show other ways to think about the structuring of "space" and the ways in which an attention to space allows one to better engage in structuring data representations that are fully responsive to their originating questions. Such a project has basic implications for how we think about neighborhood effects on individuals, most immediately in terms of the granularity we build into the representations and our sense for whether that matters for the interpretation.
We will follow a long trajectory from mathematics since the 1960s, and think about the objects of mathematics as having structure, and themselves being amenable to analyses of various sorts. This is one (of many) attempts in the academic disciplines to not begin with atomistic individuals and then build a representation of the world as the interaction of those individuals. In the social sciences one runs into discussions of the primacy of fields, relations, ecological systems, emergent forms, or complex adaptive systems. They (and others) seek to have a way of representing the social reality as having a structure that isn't simply the aggregation of individual effects. This can be because they want to find better ways of performing the aggregation - i.e., they still believe that the underlying reality is composed of individuals doing things - or it can be that they believe that the structures precede and produce the individuals in some way - i.e., that there is a natural order, a shared set of interests, commonalities in ways of acting, or constraints on the field of becoming that will result in only certain outcomes being available to the individual.  

We will see a paired problem - or opportunity - of what we may call "computability." It has to do with the choice of the basic unit around which other computations will be performed. It is a determination that is in terms of the space, as determined above, but that gives that space its "best" metric, and grounds calculation in terms of operations that fit that metric. In this case, the natural choice is the individual person, although there are times when it might be more effective to use "family" or "household" - that the households and families are ultimately made up of individuals is what grounds the final choice of the computational metric, but that choice makes it harder to model people who don't live in traditional arrangements. They end up being either implicitly or explicitly excluded from models of social dynamics based on household and family data, at sometimes hard to measure loss in the utility of the models produced. There are other ways of thinking about computability, mostly having to do with whether the internal logic of the computation guarantees completion, with famously difficult cases arising from the way that computational approaches handle infinity. Here we note that there is a complement to that question, which is merely that the sense of having completed a computation requires a meaningful unit upon which the computation terminates. That every thing that we can represent to ourselves can be represented in terms of binary code jumps to the end of the argument, and although we'll touch on that, later, the point here is to note that there are mundane senses in which computation depends on knowing what the unit of computation is, and how it relates to the operations performed on those units.
